{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4",
      "collapsed_sections": [
        "TP9qrcMfS8Id"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#í™˜ê²½ ì„¸íŒ…"
      ],
      "metadata": {
        "id": "qt64O2ABTAT6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qN0HjNa8cRY1",
        "outputId": "0eabca1e-b6de-4fd2-d88e-30bfffaac197",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m78.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m31.3/31.3 MB\u001b[0m \u001b[31m68.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m111.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m60.0/60.0 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m105.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# requirements\n",
        "!pip install -q -U langchain langchain-community faiss-cpu tiktoken pyngrok streamlit gspread oauth2client"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q flash-attn --no-build-isolation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vI_4bzJZfSAq",
        "outputId": "84ba728b-78d5-4f1d-a4fa-c0686bbd613b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/6.0 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m191.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m107.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m121.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m97.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m57.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m41.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m108.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for flash-attn (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re"
      ],
      "metadata": {
        "id": "JU8_Al-bfUSG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_rows', None)"
      ],
      "metadata": {
        "id": "OoBPgj-vdtxd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1AnVVuyGdx3c",
        "outputId": "8454f07d-8ba6-43c7-988e-1e238b06eb5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 1-Kj768zG_e2td3uPTwsDn8C5aKzRDHpA\n",
        "!gdown 1-CWb77ho-P5j1ZZTMXG7Iey4nXaFkoAr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VAUFvUy5f-Gu",
        "outputId": "543e0c67-3bbb-435e-acae-a41b6ebfdda3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-Kj768zG_e2td3uPTwsDn8C5aKzRDHpA\n",
            "To: /content/index.pkl\n",
            "100% 15.1M/15.1M [00:00<00:00, 15.4MB/s]\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1-CWb77ho-P5j1ZZTMXG7Iey4nXaFkoAr\n",
            "From (redirected): https://drive.google.com/uc?id=1-CWb77ho-P5j1ZZTMXG7Iey4nXaFkoAr&confirm=t&uuid=396f6ce6-21d5-41c6-9e1c-de02291b8d71\n",
            "To: /content/index.faiss\n",
            "100% 217M/217M [00:04<00:00, 53.8MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir faiss_index_path"
      ],
      "metadata": {
        "id": "BhhQLpj2hIfO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "try:\n",
        "  shutil.move('/content/index.faiss','/content/faiss_index_path')\n",
        "  shutil.move('/content/index.pkl','/content/faiss_index_path')\n",
        "except:\n",
        "  pass"
      ],
      "metadata": {
        "id": "Twly1lARhaNq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile config.py\n",
        "OPENAI_API_KEY = \"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\"\n",
        "FAISS_INDEX_PATH = \"/content/faiss_index_path\"\n",
        "# CSV_PATH = \"/content/á„Œá…¥á„Œá…¡á†¨á„€á…¯á†«á„‡á…¥á†¸ á„Œá…©á„†á…®á†«.csv\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dEzalgY7cYwj",
        "outputId": "496d5b5c-da6f-463a-e994-09395ba29ffe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing config.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#í”¼ë“œë°± ì €ì¥ - Google Sheet"
      ],
      "metadata": {
        "id": "TP9qrcMfS8Id"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 1beWJlnc92f3MOp_i1XSJU6AvJVomeHvr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35963815-ceed-468d-9249-ff369627507b",
        "id": "TQeSpk93TNfg"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1beWJlnc92f3MOp_i1XSJU6AvJVomeHvr\n",
            "To: /content/credentials.json\n",
            "\r  0% 0.00/2.35k [00:00<?, ?B/s]\r100% 2.35k/2.35k [00:00<00:00, 10.9MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile google_sheets.py\n",
        "import gspread\n",
        "from oauth2client.service_account import ServiceAccountCredentials\n",
        "from datetime import datetime\n",
        "\n",
        "def append_feedback_to_sheet(feedback_type, content, chat_title):\n",
        "    # âœ… êµ¬ê¸€ API ì ‘ê·¼ ë²”ìœ„ ì„¤ì •\n",
        "    scope = ['https://spreadsheets.google.com/feeds', 'https://www.googleapis.com/auth/drive']\n",
        "\n",
        "    # âœ… credentials.jsonì€ ë™ì¼ ë””ë ‰í† ë¦¬ì— ìˆì–´ì•¼ í•¨\n",
        "    creds = ServiceAccountCredentials.from_json_keyfile_name(\"credentials.json\", scope)\n",
        "    client = gspread.authorize(creds)\n",
        "\n",
        "    # âœ… ì‹¤ì œ ì‹œíŠ¸ IDë¡œ ì‹œíŠ¸ ì—´ê¸°\n",
        "    sheet_id = \"1KSPtZZagGFh-voSnLKImkpNYoJeNc8CBGhj_MrXt4QM\"\n",
        "    sheet = client.open_by_key(sheet_id).sheet1  # ì²« ë²ˆì§¸ ì‹œíŠ¸ ì‚¬ìš©\n",
        "\n",
        "    # âœ… í˜„ì¬ ì‹œê°„ê³¼ í•¨ê»˜ í•œ í–‰ ì‚½ì…\n",
        "    now = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "    sheet.append_row([now, chat_title, feedback_type, content])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88d7120c-e9c6-4171-b192-a8236a87d770",
        "id": "a6BDQHD6TNfg"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing google_sheets.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ì˜ë„ íŒŒì•… (í”„ë¡¬í”„íŠ¸ ìˆ˜ì •)"
      ],
      "metadata": {
        "id": "qtLstNTkfsLI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile intent_analysis.py\n",
        "import re\n",
        "import json\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from sentence_transformers import CrossEncoder\n",
        "\n",
        "def intent_analysis(user_input):\n",
        "    # ì‚¬ìš©ì ì§ˆë¬¸\n",
        "    # query = user_input\n",
        "    query = \"ë‹¤ë¥¸ì‚¬ëŒì˜ ì €ì‘ë¬¼ì„ ë‚´ê°€ ê±°ì§“ìœ¼ë¡œ ë“±ë¡í•˜ë©´ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?\"\n",
        "    # query = \"ê°‘ì€ ê³ ë“±í•™êµ ìŒì•…ì„ ìƒë‹˜ì¸ë°, í•™êµ ìˆ˜ì—…ì‹œê°„ì— ìŒì•…ì´ë¡ ì„ ì„¤ëª…í•˜ê¸° ìœ„í•´ì„œ ê³µí‘œë˜ì–´ ìˆëŠ” ë…¸ë˜ë¥¼ ì €ì‘ìì˜ í—ˆë½ì—†ì´ í•™ìƒë“¤ì—ê²Œ ë“¤ë ¤ì£¼ëŠ” ê²ƒì´ ì €ì‘ê¶Œë²•ìœ„ë°˜ì¸ì§€?\"\n",
        "\n",
        "    # LLM ì´ˆê¸°í™”\n",
        "    llm = ChatOpenAI(\n",
        "          temperature=0,\n",
        "          model_name = 'gpt-4-turbo',\n",
        "          openai_api_key='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'\n",
        "    )\n",
        "\n",
        "    # ì‚¬ìš©ì ì§ˆë¬¸ ì˜ë„ íŒŒì•… ########################## ìˆ˜ì • (5,6ë²ˆ ì œê±°, ì‹œí–‰ë ¹ ì¶”ê°€)\n",
        "    intent_analysis_prompt = f\"\"\"\n",
        "    ë¶„ì„ ëŒ€ìƒ ì§ˆë¬¸: {query}\n",
        "\n",
        "    ì´ ì§ˆë¬¸ì— ëŒ€í•´ ë‹¤ìŒì„ ë¶„ì„í•´ì£¼ì„¸ìš”:\n",
        "    1. ì´ ì§ˆë¬¸ì´ ì €ì‘ê¶Œë²•ì— ê´€í•œ ê²ƒì¸ì§€? (ì˜ˆ/ì•„ë‹ˆì˜¤)\n",
        "    2. ì§ˆë¬¸ì´ ë¬»ëŠ” ì£¼ìš” ë¬¸ì„œ ìœ í˜•ì€ ë¬´ì—‡ì¸ì§€? (ë²•ë ¹/íŒë¡€/í•´ì„ë¡€/ë³µí•©ì )\n",
        "    3. íŠ¹ì • ì¡°ë¬¸ì´ë‚˜ í˜¸ë¥¼ ì–¸ê¸‰í•˜ëŠ”ì§€? ì–¸ê¸‰í•œë‹¤ë©´ ì–´ë–¤ ì¡°ì™€ í˜¸ì¸ì§€?\n",
        "    4. ë§¥ë½ì  ì„¤ëª…ì´ í•„ìš”í•œ ì§ˆë¬¸ì¸ì§€? (ê°œë… ì„¤ëª…, ì°¨ì´ì  ì„¤ëª… ë“±ì„ ìš”êµ¬í•˜ëŠ”ì§€)\n",
        "\n",
        "    ê° í•­ëª©ì— ëŒ€í•´ ê°„ê²°í•˜ê²Œ ë‹µë³€í•˜ê³ , JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:\n",
        "\n",
        "    ```json\n",
        "    {{\n",
        "    \"is_copyright_related\": true/false,\n",
        "    \"document_types\": [\"ë²•ë ¹\", \"íŒë¡€\", \"í•´ì„ë¡€\", \"ì‹œí–‰ë ¹\"],\n",
        "    \"specific_article\": {{\"article\": \"ì¡°ë²ˆí˜¸\", \"ho\": \"í˜¸ë²ˆí˜¸\"}},\n",
        "    \"needs_context\": true/false\n",
        "    }}\n",
        "    \"\"\"\n",
        "\n",
        "    intent_analysis_result = llm.predict(intent_analysis_prompt)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # JSON ë¬¸ìì—´ì„ íŒŒì´ì¬ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜\n",
        "    try:\n",
        "        # JSON ë¸”ë¡ ì¶”ì¶œì„ ìœ„í•œ ì •ê·œì‹ (ë¶ˆí•„ìš”í•œ ë§ˆí¬ë‹¤ìš´ ë¬¸ë²• ì œê±°)\n",
        "        json_str = re.sub(r'```.*?\\n|```', '', intent_analysis_result.strip())\n",
        "        intent_data = json.loads(json_str)\n",
        "\n",
        "    except json.JSONDecodeError:\n",
        "        # JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ê°’ ì„¤ì •\n",
        "        intent_data = {\n",
        "            \"is_copyright_related\": True,\n",
        "            \"document_types\": [\"ë²•ë ¹\", \"íŒë¡€\", \"ì‹œí–‰ë ¹\"], ################# ìˆ˜ì • (ì‹œí–‰ë ¹ ì¶”ê°€)\n",
        "            \"specific_article\": {\"article\": \"2\", \"ho\": \"8\"},\n",
        "            \"needs_context\": True\n",
        "        }\n",
        "\n",
        "    # ë¶„ì„ ê²°ê³¼ ì¶”ì¶œ\n",
        "    is_copyright_related = intent_data.get(\"is_copyright_related\", True)\n",
        "    document_types = intent_data.get(\"document_types\", [\"ë²•ë ¹\", \"íŒë¡€\", \"ì‹œí–‰ë ¹\"])\n",
        "    specific_article = intent_data.get(\"specific_article\", {\"article\": \"2\", \"ho\": \"8\"})\n",
        "    needs_context = intent_data.get(\"needs_context\", True)\n",
        "\n",
        "    return {\n",
        "        \"is_copyright_related\": is_copyright_related,\n",
        "        \"document_types\": document_types,\n",
        "        \"specific_article\": specific_article,\n",
        "        \"needs_context\": needs_context\n",
        "    }"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q3jXAKv_fwP1",
        "outputId": "ad354f28-ca41-4c91-e422-c3dfebea909a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing intent_analysis.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ë¦¬íŠ¸ë¦¬ë²„ (í”„ë¡¬í”„íŠ¸ ìˆ˜ì •)"
      ],
      "metadata": {
        "id": "0NDiedgtTVyU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# %%writefile generate_multiquery_and_retrieve.py\n",
        "# from langchain.prompts import PromptTemplate\n",
        "# from langchain.retrievers.multi_query import MultiQueryRetriever\n",
        "# from langchain.retrievers.contextual_compression import ContextualCompressionRetriever  # (í•„ìš” ì‹œ)\n",
        "# from langchain.chat_models import ChatOpenAI\n",
        "# from transformers import AutoModel\n",
        "# from intent_analysis import intent_analysis\n",
        "\n",
        "# def generate_multiquery_and_retrieve(query, retry_num, retriever, llm, model):\n",
        "#     intent_result = intent_analysis(query)\n",
        "#     # retry_numì— ë”°ë¥¸ ë‹¤ì–‘í•œ í”„ë¡¬í”„íŠ¸ êµ¬ì„±##################################### (ìˆ˜ì •: needs_context ì¶”ê°€ ë° í”„ë¡¬í”„íŠ¸ ìˆ˜ì •)\n",
        "\n",
        "#     if intent_result['needs_context'] and retry_num == 0:\n",
        "#         prompt_template = f\"\"\"\n",
        "#         ì‚¬ìš©ì ì§ˆë¬¸: {query}\n",
        "\n",
        "#         ì´ ì§ˆë¬¸ì€ ë²•ë¥ ì  ê°œë…ì— ëŒ€í•œ ë§¥ë½ì  ì„¤ëª…ì´ í•„ìš”í•©ë‹ˆë‹¤.\n",
        "#         ë”°ë¼ì„œ ì´ ì§ˆë¬¸ê³¼ ì˜ë¯¸ëŠ” ê°™ì§€ë§Œ ë‹¤ë¥¸ í‘œí˜„ìœ¼ë¡œ ê²€ìƒ‰í•  ìˆ˜ ìˆëŠ” 3ê°€ì§€ ë‹¤ë¥¸ ì§ˆë¬¸ì„ ìƒì„±í•´ì£¼ì„¸ìš”.\n",
        "#         ë‹¤ìŒê³¼ ê°™ì€ ë‹¤ì–‘í•œ ê´€ì ì—ì„œ ì§ˆë¬¸ì„ ì‘ì„±í•´ì£¼ì„¸ìš”:\n",
        "#         1. ë²•ë ¹ ê²€ìƒ‰ì— ìµœì í™”ëœ ì§ˆë¬¸\n",
        "#         2. íŒë¡€ ê²€ìƒ‰ì— ìµœì í™”ëœ ì§ˆë¬¸\n",
        "#         3. ë²•ë¥  í•´ì„ ê²€ìƒ‰ì— ìµœì í™”ëœ ì§ˆë¬¸\n",
        "\n",
        "#         ì§ˆë¬¸ ëª©ë¡ë§Œ ì¤„ë°”ê¿ˆìœ¼ë¡œ êµ¬ë¶„í•˜ì—¬ ì‘ì„±í•´ì£¼ì„¸ìš”.\n",
        "#         \"\"\"\n",
        "#     elif intent_result['needs_context'] and retry_num == 1:\n",
        "#         prompt_template = f\"\"\"\n",
        "#         ì•„ë˜ ì§ˆë¬¸ì— ëŒ€í•œ ë§¥ë½ì  ì„¤ëª…ì„ ìœ„í•´ ë” ë‹¤ì–‘í•œ í‚¤ì›Œë“œì™€ ì‹œê°ìœ¼ë¡œ ì¬í•´ì„í•˜ì—¬ ê²€ìƒ‰ ì¿¼ë¦¬ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”:\n",
        "#         {query}\n",
        "\n",
        "#         - ë²•ë¥ ì  í‚¤ì›Œë“œ ë° ë™ì˜ì–´ë¥¼ í¬í•¨í•´ì£¼ì„¸ìš”.\n",
        "#         - ì§ˆë¬¸ì˜ ë§¥ë½ì„ í™•ì¥í•˜ê±°ë‚˜ ë³€í˜•í•˜ì—¬ ê²€ìƒ‰ì— ë„ì›€ì´ ë˜ë„ë¡ ë°”ê¿”ì£¼ì„¸ìš”.\n",
        "\n",
        "#         3ê°œì˜ ì§ˆë¬¸ì„ ì¤„ë°”ê¿ˆìœ¼ë¡œ êµ¬ë¶„í•´ì£¼ì„¸ìš”.\n",
        "#         \"\"\"\n",
        "#     elif retry_num == 2:\n",
        "#         prompt_template = f\"\"\"\n",
        "#         ì•„ë˜ ì§ˆë¬¸ì— ëŒ€í•´ ë‹¤ì–‘í•œ ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ìƒìƒí•˜ë©° ê²€ìƒ‰ì— ë„ì›€ì´ ë˜ëŠ” ì¿¼ë¦¬ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”:\n",
        "#         {query}\n",
        "\n",
        "#         - íŒë¡€, í•´ì„ë¡€, ë²•ë ¹ ë“±ì—ì„œ ìœ ì‚¬ ìƒí™©ì„ ë– ì˜¬ë¦¬ë©° ì§ˆë¬¸ì„ êµ¬ì„±í•´ì£¼ì„¸ìš”.\n",
        "#         - ì˜ë¯¸ëŠ” ìœ ì§€í•˜ë˜ í‘œí˜„ì€ ìƒˆë¡­ê²Œ êµ¬ì„±í•´ì£¼ì„¸ìš”.\n",
        "\n",
        "#         ì¤„ë°”ê¿ˆìœ¼ë¡œ êµ¬ë¶„ëœ 3ê°œì˜ ì§ˆë¬¸ë§Œ ì‘ì„±í•´ì£¼ì„¸ìš”.\n",
        "#         \"\"\"\n",
        "#     else:\n",
        "#         prompt_template = f\"{query}\"\n",
        "\n",
        "#     # ë©€í‹°ì¿¼ë¦¬ ìƒì„±\n",
        "#     new_queries = llm.predict(prompt_template).strip().split('\\n')\n",
        "#     new_queries = [q.strip() for q in new_queries if q.strip()]\n",
        "#     # print(f\"\\n[ë©€í‹°ì¿¼ë¦¬ {retry_num+1}íšŒì°¨ ìƒì„± ê²°ê³¼] {new_queries}\")\n",
        "\n",
        "#     # ë©€í‹°ì¿¼ë¦¬ ë¦¬íŠ¸ë¦¬ë²„ êµ¬ì„±\n",
        "#     prompt_obj = PromptTemplate.from_template(prompt_template)\n",
        "#     multiquery_retriever = MultiQueryRetriever.from_llm(\n",
        "#         retriever=retriever,\n",
        "#         llm=llm,\n",
        "#         prompt=prompt_obj\n",
        "#     )\n",
        "\n",
        "#     # ë¦¬ë­í‚¹\n",
        "#     docs = multiquery_retriever.invoke(query)\n",
        "#     text_pairs = [[query, doc.page_content] for doc in docs]\n",
        "#     scores = model.compute_score(text_pairs, doc_type=\"text\")\n",
        "\n",
        "#     # ì ìˆ˜ì™€ docs ë¬¶ê¸°\n",
        "#     scored_docs = list(zip(scores, docs))\n",
        "\n",
        "#     # ì ìˆ˜ ê¸°ì¤€ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬ í›„ ìƒìœ„ 3ê°œ ì„¤ì •\n",
        "#     top_k = sorted(scored_docs, key=lambda x: x[0], reverse=True)[:3]\n",
        "\n",
        "#     # ì¤‘ë³µ ë¬¸ì„œ í•„í„°ë§\n",
        "#     filtered_docs = []\n",
        "#     seen_contents = set()\n",
        "\n",
        "#     # print(\"\\n=== ì¤‘ë³µ ë¬¸ì„œ í•„í„°ë§ ===\")\n",
        "#     # print(f\"í•„í„°ë§ ì „ ë¬¸ì„œ ìˆ˜: {len(top_k)}\")\n",
        "#     for score, doc in top_k:\n",
        "#         # ë¬¸ì„œ ë‚´ìš© ì •ì œ (ê°„ë‹¨í•œ ë°©ì‹ìœ¼ë¡œ)\n",
        "#         # ê³µë°± ë° íŠ¹ìˆ˜ë¬¸ì ì œê±°í•˜ê³  ì†Œë¬¸ìí™”í•˜ì—¬ ë¹„êµ\n",
        "#         content = doc.page_content\n",
        "\n",
        "#         # í…ìŠ¤íŠ¸ ì •ì œ (ë¹„êµë¥¼ ìœ„í•œ ê°„ì†Œí™”)\n",
        "#         simplified_content = ''.join(char.lower() for char in content if char.isalnum())\n",
        "\n",
        "#         # ë¬¸ì„œ ë‚´ìš© ì¤‘ ì¼ë¶€ë§Œ ì‚¬ìš©í•˜ì—¬ ì¤‘ë³µ íŒë‹¨ (ì²˜ìŒ 300ì) ########################## ìˆ˜ì • (100ì->300ì)\n",
        "#         content_key = simplified_content[:300]\n",
        "\n",
        "#         # ì´ë¯¸ ë¹„ìŠ·í•œ ë‚´ìš©ì˜ ë¬¸ì„œê°€ í¬í•¨ë˜ì—ˆëŠ”ì§€ í™•ì¸\n",
        "#         if content_key not in seen_contents:\n",
        "#             filtered_docs.append(doc)\n",
        "#             seen_contents.add(content_key)\n",
        "\n",
        "#     # print(f\"ğŸ“„ í•„í„°ë§ í›„ ë¬¸ì„œ ìˆ˜: {len(filtered_docs)}\")\n",
        "#     return filtered_docs"
      ],
      "metadata": {
        "id": "wKRB3yVuhEbW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df18b269-7265-4ae1-ceaa-ba7d4562f4f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing generate_multiquery_and_retrieve.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile generate_multiquery_and_retrieve.py\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
        "from langchain.retrievers.contextual_compression import ContextualCompressionRetriever  # (í•„ìš” ì‹œ)\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from transformers import AutoModel\n",
        "from intent_analysis import intent_analysis\n",
        "import re\n",
        "\n",
        "def generate_multiquery_and_retrieve(query, retry_num, retriever, llm, model):\n",
        "    intent_result = intent_analysis(query)\n",
        "    # retry_numì— ë”°ë¥¸ ë‹¤ì–‘í•œ í”„ë¡¬í”„íŠ¸ êµ¬ì„±##################################### (ìˆ˜ì •: needs_context ì¶”ê°€ ë° í”„ë¡¬í”„íŠ¸ ìˆ˜ì •)\n",
        "\n",
        "    if intent_result['needs_context'] and retry_num == 0:\n",
        "        prompt_template = f\"\"\"\n",
        "        ì‚¬ìš©ì ì§ˆë¬¸: {query}\n",
        "\n",
        "        ì´ ì§ˆë¬¸ì€ ë²•ë¥ ì  ê°œë…ì— ëŒ€í•œ ë§¥ë½ì  ì„¤ëª…ì´ í•„ìš”í•©ë‹ˆë‹¤.\n",
        "        ë”°ë¼ì„œ ì´ ì§ˆë¬¸ê³¼ ì˜ë¯¸ëŠ” ê°™ì§€ë§Œ ë‹¤ë¥¸ í‘œí˜„ìœ¼ë¡œ ê²€ìƒ‰í•  ìˆ˜ ìˆëŠ” 3ê°€ì§€ ë‹¤ë¥¸ ì§ˆë¬¸ì„ ìƒì„±í•´ì£¼ì„¸ìš”.\n",
        "        ë‹¤ìŒê³¼ ê°™ì€ ë‹¤ì–‘í•œ ê´€ì ì—ì„œ ì§ˆë¬¸ì„ ì‘ì„±í•´ì£¼ì„¸ìš”:\n",
        "        1. ë²•ë ¹ ê²€ìƒ‰ì— ìµœì í™”ëœ ì§ˆë¬¸\n",
        "        2. íŒë¡€ ê²€ìƒ‰ì— ìµœì í™”ëœ ì§ˆë¬¸\n",
        "        3. ë²•ë¥  í•´ì„ ê²€ìƒ‰ì— ìµœì í™”ëœ ì§ˆë¬¸\n",
        "\n",
        "        ì§ˆë¬¸ ëª©ë¡ë§Œ ì¤„ë°”ê¿ˆìœ¼ë¡œ êµ¬ë¶„í•˜ì—¬ ì‘ì„±í•´ì£¼ì„¸ìš”.\n",
        "        \"\"\"\n",
        "    elif intent_result['needs_context'] and retry_num == 1:\n",
        "        prompt_template = f\"\"\"\n",
        "        ì•„ë˜ ì§ˆë¬¸ì— ëŒ€í•œ ë§¥ë½ì  ì„¤ëª…ì„ ìœ„í•´ ë” ë‹¤ì–‘í•œ í‚¤ì›Œë“œì™€ ì‹œê°ìœ¼ë¡œ ì¬í•´ì„í•˜ì—¬ ê²€ìƒ‰ ì¿¼ë¦¬ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”:\n",
        "        {query}\n",
        "\n",
        "        - ë²•ë¥ ì  í‚¤ì›Œë“œ ë° ë™ì˜ì–´ë¥¼ í¬í•¨í•´ì£¼ì„¸ìš”.\n",
        "        - ì§ˆë¬¸ì˜ ë§¥ë½ì„ í™•ì¥í•˜ê±°ë‚˜ ë³€í˜•í•˜ì—¬ ê²€ìƒ‰ì— ë„ì›€ì´ ë˜ë„ë¡ ë°”ê¿”ì£¼ì„¸ìš”.\n",
        "\n",
        "        3ê°œì˜ ì§ˆë¬¸ì„ ì¤„ë°”ê¿ˆìœ¼ë¡œ êµ¬ë¶„í•´ì£¼ì„¸ìš”.\n",
        "        \"\"\"\n",
        "    elif retry_num == 2:\n",
        "        prompt_template = f\"\"\"\n",
        "        ì•„ë˜ ì§ˆë¬¸ì— ëŒ€í•´ ë‹¤ì–‘í•œ ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ìƒìƒí•˜ë©° ê²€ìƒ‰ì— ë„ì›€ì´ ë˜ëŠ” ì¿¼ë¦¬ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”:\n",
        "        {query}\n",
        "\n",
        "        - íŒë¡€, í•´ì„ë¡€, ë²•ë ¹ ë“±ì—ì„œ ìœ ì‚¬ ìƒí™©ì„ ë– ì˜¬ë¦¬ë©° ì§ˆë¬¸ì„ êµ¬ì„±í•´ì£¼ì„¸ìš”.\n",
        "        - ì˜ë¯¸ëŠ” ìœ ì§€í•˜ë˜ í‘œí˜„ì€ ìƒˆë¡­ê²Œ êµ¬ì„±í•´ì£¼ì„¸ìš”.\n",
        "\n",
        "        ì¤„ë°”ê¿ˆìœ¼ë¡œ êµ¬ë¶„ëœ 3ê°œì˜ ì§ˆë¬¸ë§Œ ì‘ì„±í•´ì£¼ì„¸ìš”.\n",
        "        \"\"\"\n",
        "    else:\n",
        "        prompt_template = f\"{query}\"\n",
        "\n",
        "    # ë©€í‹°ì¿¼ë¦¬ ìƒì„±\n",
        "    new_queries = llm.predict(prompt_template).strip().split('\\n')\n",
        "    new_queries = [q.strip() for q in new_queries if q.strip()]\n",
        "    # print(f\"\\n[ë©€í‹°ì¿¼ë¦¬ {retry_num+1}íšŒì°¨ ìƒì„± ê²°ê³¼] {new_queries}\")\n",
        "\n",
        "    # ë©€í‹°ì¿¼ë¦¬ ë¦¬íŠ¸ë¦¬ë²„ êµ¬ì„±\n",
        "    prompt_obj = PromptTemplate.from_template(prompt_template)\n",
        "    multiquery_retriever = MultiQueryRetriever.from_llm(\n",
        "        retriever=retriever,\n",
        "        llm=llm,\n",
        "        prompt=prompt_obj\n",
        "    )\n",
        "\n",
        "    # ë¦¬ë­í‚¹\n",
        "    docs = multiquery_retriever.invoke(query)\n",
        "    text_pairs = [[query, doc.page_content] for doc in docs]\n",
        "    scores = model.compute_score(text_pairs, doc_type=\"text\")\n",
        "\n",
        "    # ì ìˆ˜ì™€ docs ë¬¶ê¸°\n",
        "    scored_docs = list(zip(scores, docs))\n",
        "\n",
        "    # ì ìˆ˜ ê¸°ì¤€ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬ í›„ ìƒìœ„ 3ê°œ ì„¤ì •\n",
        "    top_k = sorted(scored_docs, key=lambda x: x[0], reverse=True)[:3]\n",
        "\n",
        "    # ì¤‘ë³µ ë¬¸ì„œ í•„í„°ë§\n",
        "    filtered_docs = []\n",
        "\n",
        "    # print(\"\\n=== ê°„ë‹¨í•œ ì¤‘ë³µ ë¬¸ì„œ í•„í„°ë§ ===\")\n",
        "    # print(f\"í•„í„°ë§ ì „ ë¬¸ì„œ ìˆ˜: {len(top_k)}\")\n",
        "\n",
        "    for i, (score, doc) in enumerate(top_k):\n",
        "        content = doc.page_content\n",
        "        is_duplicate = False\n",
        "\n",
        "        for j, existing_doc in enumerate(filtered_docs):\n",
        "            existing_content = existing_doc.page_content\n",
        "\n",
        "            # í•µì‹¬ í‚¤ì›Œë“œë“¤ì„ ì¶”ì¶œí•˜ì—¬ ë¹„êµ (3ê¸€ì ì´ìƒ í•œê¸€ ë‹¨ì–´)\n",
        "            current_keywords = set(re.findall(r'[ê°€-í£]{3,}', content))\n",
        "            existing_keywords = set(re.findall(r'[ê°€-í£]{3,}', existing_content))\n",
        "\n",
        "            # Jaccard ìœ ì‚¬ë„ ê³„ì‚° (êµì§‘í•©/í•©ì§‘í•©)\n",
        "            if current_keywords and existing_keywords:\n",
        "                intersection = current_keywords.intersection(existing_keywords)\n",
        "                union = current_keywords.union(existing_keywords)\n",
        "                jaccard_similarity = len(intersection) / len(union)\n",
        "\n",
        "                print(f\"ë¬¸ì„œ {i+1} vs ê¸°ì¡´ ë¬¸ì„œ {j+1}: Jaccard ìœ ì‚¬ë„ = {jaccard_similarity:.3f}\")\n",
        "\n",
        "                # 70% ì´ìƒ ìœ ì‚¬í•˜ë©´ ì¤‘ë³µìœ¼ë¡œ íŒë‹¨\n",
        "                if jaccard_similarity > 0.7:\n",
        "                    is_duplicate = True\n",
        "                    print(f\"  â†’ ì¤‘ë³µìœ¼ë¡œ íŒë‹¨ë¨!\")\n",
        "                    break\n",
        "\n",
        "        if not is_duplicate:\n",
        "            filtered_docs.append(doc)\n",
        "            # print(f\"ë¬¸ì„œ {len(filtered_docs)} ì¶”ê°€: {content[:50]}...\")\n",
        "        # else:\n",
        "            # print(f\"ì¤‘ë³µ ë¬¸ì„œ ì œì™¸: {content[:50]}...\")\n",
        "    return filtered_docs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "812c390c-393f-4b5d-d636-363e4ec3ab9d",
        "id": "8jTNNLPFEhHT"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting generate_multiquery_and_retrieve.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#í‰ê°€ (í•¨ìˆ˜ ìˆ˜ì •)"
      ],
      "metadata": {
        "id": "O3pk-7nfgOqQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q ragas"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RwtuWl5_gP-Y",
        "outputId": "41b6ca1a-e87a-4018-896c-0723f8f989ea",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/190.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m190.9/190.9 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/45.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/63.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m63.4/63.4 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/438.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m438.3/438.3 kB\u001b[0m \u001b[31m38.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile generate_answer_and_evaluate.py\n",
        "import os\n",
        "import re\n",
        "import json\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from ragas import EvaluationDataset, evaluate\n",
        "from ragas.llms import LangchainLLMWrapper\n",
        "from ragas.metrics import Faithfulness, ResponseRelevancy\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
        "\n",
        "ragas_llm = ChatOpenAI(model=\"gpt-4o\")\n",
        "ragas_embeddings = OpenAIEmbeddings()\n",
        "\n",
        "def generate_answer_and_evaluate(query, filtered_docs, llm): ################################ ìˆ˜ì • (í•¨ìˆ˜ ì „ì²´ì ìœ¼ë¡œ ìˆ˜ì •- ë¬¸ì„œ ì²˜ë¦¬)\n",
        "    # í”„ë¡¬í”„íŠ¸ êµ¬ì„±\n",
        "    final_ref = []\n",
        "    response_prompt = f\"ë‹¤ìŒì€ '{query}'ì— ëŒ€í•œ ê´€ë ¨ ì •ë³´ì…ë‹ˆë‹¤:\\n\\n\"\n",
        "\n",
        "    # ì¤‘ë³µì´ ì œê±°ëœ ë¬¸ì„œë“¤ì„ í”„ë¡¬í”„íŠ¸ì— ì¶”ê°€\n",
        "    for i, doc in enumerate(filtered_docs):\n",
        "        doc_type = doc.metadata.get('ë¬¸ì„œìœ í˜•', '')\n",
        "\n",
        "        # ë¬¸ì„œ ë‚´ìš© ê°€ì ¸ì˜¤ê¸°\n",
        "        content = doc.page_content\n",
        "\n",
        "        # ë¯¸ì™„ì„± ë¬¸ì¥ ì²˜ë¦¬ (ì—¬ëŸ¬ íŒ¨í„´ ëŒ€ì‘)\n",
        "\n",
        "        # ê´„í˜¸ ë°¸ëŸ°ìŠ¤ í™•ì¸ ë° ìˆ˜ì •\n",
        "        def fix_unbalanced_parentheses(text):\n",
        "            # ì—´ë¦° ê´„í˜¸ì™€ ë‹«íŒ ê´„í˜¸ ê°œìˆ˜ í™•ì¸\n",
        "            open_count = text.count('(')\n",
        "            close_count = text.count(')')\n",
        "\n",
        "            # ê´„í˜¸ ë¶ˆê· í˜• í™•ì¸\n",
        "            if open_count > close_count:\n",
        "                # ì—´ë¦° ê´„í˜¸ê°€ ë” ë§ì€ ê²½ìš°, ë§ˆì§€ë§‰ ì™„ì „í•œ ê´„í˜¸ êµ¬ë¬¸ ì´í›„ ë‚´ìš© ì œê±°\n",
        "                # ê°€ì¥ ë§ˆì§€ë§‰ ë‹«íŒ ê´„í˜¸ ìœ„ì¹˜ ì°¾ê¸°\n",
        "                last_close_idx = text.rfind(')')\n",
        "                if last_close_idx > 0:\n",
        "                    # í•´ë‹¹ ë‹«íŒ ê´„í˜¸ì™€ ì§ì„ ì´ë£¨ëŠ” ì—´ë¦° ê´„í˜¸ ì°¾ê¸° ì‹œë„\n",
        "                    stack = []\n",
        "                    for idx, char in enumerate(text[:last_close_idx+1]):\n",
        "                        if char == '(':\n",
        "                            stack.append(idx)\n",
        "                        elif char == ')':\n",
        "                            if stack:  # ì§ì´ ë§ëŠ” ì—´ë¦° ê´„í˜¸ê°€ ìˆìœ¼ë©´ pop\n",
        "                                stack.pop()\n",
        "                            # ìŠ¤íƒì´ ë¹„ì–´ìˆìœ¼ë©´ ì§ì´ ì•ˆ ë§ëŠ” ë‹«íŒ ê´„í˜¸\n",
        "\n",
        "                    # ì•„ì§ ì§ì´ ì—†ëŠ” ì—´ë¦° ê´„í˜¸ê°€ ìˆëŠ” ê²½ìš°\n",
        "                    if stack:\n",
        "                        # ê°€ì¥ ë§ˆì§€ë§‰ ì§ì´ ë§ëŠ” ê´„í˜¸ êµ¬ì¡° ì´í›„ ìœ„ì¹˜ ì°¾ê¸°\n",
        "                        pos = last_close_idx + 1\n",
        "                        # ë¶ˆì™„ì „í•œ êµ¬ë¬¸ì„ ì œê±°í•˜ê³  ì¤‘ëµ í‘œì‹œ ì¶”ê°€\n",
        "                        return text[:pos] + \"...(í›„ëµ)\"\n",
        "\n",
        "            # ë‹«íŒ ê´„í˜¸ê°€ ë” ë§ì€ ê²½ìš°, ì²« ë²ˆì§¸ ë‹«íŒ ê´„í˜¸ ìœ„ì¹˜ ì „ê¹Œì§€ë§Œ ì‚¬ìš©\n",
        "            elif close_count > open_count:\n",
        "                first_unmatched_close = -1\n",
        "                stack = []\n",
        "                for idx, char in enumerate(text):\n",
        "                    if char == '(':\n",
        "                        stack.append(idx)\n",
        "                    elif char == ')':\n",
        "                        if stack:  # ì§ì´ ë§ëŠ” ì—´ë¦° ê´„í˜¸ê°€ ìˆìœ¼ë©´ pop\n",
        "                            stack.pop()\n",
        "                        else:  # ì§ì´ ì—†ëŠ” ì²« ë²ˆì§¸ ë‹«íŒ ê´„í˜¸ ì°¾ê¸°\n",
        "                            first_unmatched_close = idx\n",
        "                            break\n",
        "\n",
        "                if first_unmatched_close > 0:\n",
        "                    return \"(ì „ëµ)... \" + text[first_unmatched_close+1:]\n",
        "\n",
        "            # ê´„í˜¸ê°€ ê· í˜•ì„ ì´ë£¨ê±°ë‚˜ ìˆ˜ì •ì´ í•„ìš”ì—†ëŠ” ê²½ìš°\n",
        "            return text\n",
        "\n",
        "        # íŒë¡€ ì¸ìš© íŒ¨í„´ ì²˜ë¦¬\n",
        "        def fix_case_citation(text):\n",
        "            # \"ì„ ê³  OOë‹¤OO íŒê²° ì°¸ì¡°), \" íŒ¨í„´ ì°¾ê¸°\n",
        "            pattern = r'ì„ ê³ \\s+\\d+\\s*ë‹¤\\s*\\d+\\s*íŒê²°\\s*ì°¸ì¡°\\)\\s*,'\n",
        "            match = re.search(pattern, text)\n",
        "            if match:\n",
        "                # ë§¤ì¹˜ëœ ë¶€ë¶„ì˜ ë ìœ„ì¹˜\n",
        "                end_pos = match.end()\n",
        "                # ì•ë¶€ë¶„ì€ ìœ ì§€í•˜ê³  íŒ¨í„´ ì´í›„ì˜ ë‚´ìš©ì€ ì¤‘ëµ í‘œì‹œë¡œ ëŒ€ì²´\n",
        "                return text[:end_pos] + \" ...(ì¤‘ëµ)\"\n",
        "            return text\n",
        "\n",
        "        #### ë¯¸ì™„ì„± ë¬¸ì¥ ì²˜ë¦¬ (ì—¬ëŸ¬ íŒ¨í„´ ëŒ€ì‘) ###\n",
        "\n",
        "        # íŒë¡€ ì¸ìš© íŒ¨í„´ ì²˜ë¦¬\n",
        "        content = fix_case_citation(content)\n",
        "\n",
        "        # ê´„í˜¸ ë°¸ëŸ°ìŠ¤ í™•ì¸ ë° ìˆ˜ì •\n",
        "        content = fix_unbalanced_parentheses(content)\n",
        "\n",
        "        # ë‚´ìš©ì´ ì‰¼í‘œ(,)ë¡œ ì‹œì‘í•˜ëŠ” ê²½ìš° ì²˜ë¦¬\n",
        "        if content.strip().startswith(','):\n",
        "            content = \"...(ì¤‘ëµ) \" + content.strip()[1:].strip()\n",
        "\n",
        "        # ë¬¸ì¥ì´ íŠ¹ì • íŒ¨í„´ìœ¼ë¡œ ì‹œì‘í•˜ëŠ” ê²½ìš°\n",
        "        if content.startswith('.') or content.startswith(')') or re.match(r'^\\s*[0-9]+\\.', content):\n",
        "            content = re.sub(r'^\\.\\s*', '', content)\n",
        "\n",
        "        # ë¯¸ì™„ì„± ë¬¸ì¥ì´ ëë‚˜ëŠ” ê²½ìš°\n",
        "        if content.endswith('(') or content.endswith(',') or re.search(r'[a-zA-Zê°€-í£]\\s*$', content):\n",
        "            content = content.strip() + \"...\"\n",
        "\n",
        "        # ê¸°ì¡´ ì½”ë“œì˜ ë¯¸ì™„ì„± ë¬¸ì¥ ì²˜ë¦¬ (ì ìœ¼ë¡œ ì‹œì‘í•˜ëŠ” ê²½ìš°)\n",
        "        if content.startswith('.'):\n",
        "            content = re.sub(r'^\\.\\s*[^.]*\\)\\s*', '', content)\n",
        "\n",
        "        # ì½œë¡ (:) ë‹¤ìŒì— ì½¤ë§ˆ(,)ê°€ ì˜¤ëŠ” ê²½ìš° ì²˜ë¦¬\n",
        "        content = re.sub(r':\\s*,\\s*', '', content)\n",
        "\n",
        "        # ë¬¸ì¥ì´ \"ì´\" ë˜ëŠ” \"í™”\"ì™€ ê°™ì€ í•œê¸€ í•œ ê¸€ìë¡œ ëë‚˜ëŠ” ê²½ìš° (ì˜ë¦° ë¬¸ì¥)\n",
        "        if re.search(r'[ê°€-í£]\\s*$', content) and len(content.strip()) > 0:\n",
        "            last_char = content.strip()[-1]\n",
        "            # ë¬¸ì¥ ì¢…ê²° ì¡°ì‚¬ê°€ ì•„ë‹Œ ê²½ìš°ì—ë§Œ ì²˜ë¦¬\n",
        "            if last_char not in ['ë‹¤', 'ê¹Œ', 'ìš”', 'ì£ ', 'ì–', 'ì£ ', 'ë„¤', 'ìš”', 'ì„']:\n",
        "                # ë§ˆì§€ë§‰ ì™„ì „í•œ ë¬¸ì¥ ì°¾ê¸°\n",
        "                last_sentence_end = max(content.rfind('. '), content.rfind('.\\n'), content.rfind('? '), content.rfind('! '))\n",
        "                if last_sentence_end > 0:\n",
        "                    # ë§ˆì§€ë§‰ ì™„ì „í•œ ë¬¸ì¥ê¹Œì§€ë§Œ ìœ ì§€í•˜ê³  ë‚˜ë¨¸ì§€ëŠ” ì œê±°\n",
        "                    content = content[:last_sentence_end+1] + \" ...(í›„ëµ)\"\n",
        "                else:\n",
        "                    # ì™„ì „í•œ ë¬¸ì¥ êµ¬ë¶„ì´ ì—†ìœ¼ë©´ ê·¸ëŒ€ë¡œ ... ì¶”ê°€\n",
        "                    content = content.strip() + \"...\"\n",
        "\n",
        "        # íŠ¹ì • íŒë¡€ ì¸ìš© íŒ¨í„´ ì²˜ë¦¬ (ì˜ˆ: \"7. 12. ì„ ê³  77ë‹¤90 íŒê²° ì°¸ì¡°),\")\n",
        "        pattern = r'\\d+\\.\\s*\\d+\\.\\s*ì„ ê³ \\s+\\d+ë‹¤\\d+\\s*íŒê²°\\s*ì°¸ì¡°\\)\\s*,\\s*'\n",
        "        if re.search(pattern, content):\n",
        "            match = re.search(pattern, content)\n",
        "            if match:\n",
        "                end_pos = match.end()\n",
        "                if end_pos < len(content):\n",
        "                    # íŒ¨í„´ ì´í›„ ë‚´ìš©ì´ í•œ ë¬¸ì¥ ì´ìƒì¸ ê²½ìš°ì—ë§Œ ì¤‘ëµ ì²˜ë¦¬\n",
        "                    sentences_after = re.split(r'[.!?]\\s+', content[end_pos:])\n",
        "                    if len(sentences_after) > 1 and len(sentences_after[0]) > 20:\n",
        "                        content = content[:end_pos] + \"...(ì´í•˜ ìƒëµ)\"\n",
        "\n",
        "        # ë§¨ ì•ì— ìˆ«ì í•˜ë‚˜ë§Œ ìˆëŠ” ê²½ìš° ì²˜ë¦¬\n",
        "        content = re.sub(r'^\\s*(\\d+)\\s+', '', content)\n",
        "\n",
        "        # ë¹ˆ ë¬¸ì¥ì´ë‚˜ íŠ¹ìˆ˜ë¬¸ìë§Œ ìˆëŠ” ë¬¸ì¥ í•„í„°ë§\n",
        "        content = content.strip()\n",
        "        if not content or content in ['.', ',', ')', '(']:\n",
        "            continue\n",
        "\n",
        "        # ë¬¸ì„œ ìœ í˜•ì— ë”°ë¥¸ ì°¸ì¡° í˜•ì‹ ìƒì„± ################################################# ìˆ˜ì •(ë¶€ì¹™, ì‹œí–‰ë ¹, í•´ì„ë¡€ ì²˜ë¦¬ ì•ˆëë˜ ë¶€ë¶„ ìˆ˜ì •)\n",
        "        if doc_type == 'ë²•ë ¹':\n",
        "            article_num = doc.metadata.get('ì¡°ë¬¸ë²ˆí˜¸', '')\n",
        "            article_title = doc.metadata.get('ì¡°ë¬¸ì œëª©', '')\n",
        "            ho_num = doc.metadata.get('í˜¸ë²ˆí˜¸', '')\n",
        "\n",
        "            if ho_num:\n",
        "                reference = f\"[ë²•ë ¹ {i+1}] ì €ì‘ê¶Œë²• ì œ{article_num} {article_title} ì œ{ho_num}í˜¸: {content}\"\n",
        "            else:\n",
        "                reference = f\"[ë²•ë ¹ {i+1}] ì €ì‘ê¶Œë²• ì œ{article_num} {article_title}: {content}\"\n",
        "\n",
        "        elif doc_type == 'ì‹œí–‰ë ¹':\n",
        "            ord_num = doc.metadata.get('ì‹œí–‰ë ¹_ì¡°ë¬¸ë²ˆí˜¸', '')\n",
        "            ord_title = doc.metadata.get('ì‹œí–‰ë ¹_ì¡°ë¬¸ì œëª©', '')\n",
        "            ord_ho_num = doc.metadata.get('í˜¸ë²ˆí˜¸', '')\n",
        "\n",
        "            if ord_ho_num:  # 'ho_num'ì´ ì•„ë‹Œ 'ord_ho_num' ì‚¬ìš© (ë³€ìˆ˜ëª… ìˆ˜ì •)\n",
        "                reference = f\"[ë²•ë ¹ {i+1}] ì €ì‘ê¶Œë²• ì‹œí–‰ë ¹ ì œ{ord_num} {ord_title} ì œ{ord_ho_num}í˜¸: {content}\"\n",
        "            else:\n",
        "                reference = f\"[ë²•ë ¹ {i+1}] ì €ì‘ê¶Œë²• ì‹œí–‰ë ¹ ì œ{ord_num} {ord_title}: {content}\"\n",
        "\n",
        "        elif doc_type == 'ë¶€ì¹™':\n",
        "            sub_num = doc.metadata.get('ë¶€ì¹™_ì¡°ë¬¸ë²ˆí˜¸', '')\n",
        "            sub_title = doc.metadata.get('ë¶€ì¹™_ì¡°ë¬¸ì œëª©', '')\n",
        "            hang_num = doc.metadata.get('í•­ë²ˆí˜¸', '')\n",
        "\n",
        "            if hang_num:  # 'ho_num'ì´ ì•„ë‹Œ 'hang_num' ì‚¬ìš© (ë³€ìˆ˜ëª… ìˆ˜ì •)\n",
        "                reference = f\"[ë²•ë ¹ {i+1}] ì €ì‘ê¶Œë²• ë¶€ì¹™ ì œ{sub_num} {sub_title} ì œ{hang_num}í˜¸: {content}\"\n",
        "            else:\n",
        "                reference = f\"[ë²•ë ¹ {i+1}] ì €ì‘ê¶Œë²• ë¶€ì¹™ ì œ{sub_num} {sub_title}: {content}\"\n",
        "\n",
        "        elif doc_type == 'íŒë¡€':\n",
        "            case_num = doc.metadata.get('ì‚¬ê±´ë²ˆí˜¸', doc.metadata.get('íŒë¡€ë²ˆí˜¸', ''))\n",
        "            case_date = doc.metadata.get('ì„ ê³ ì¼ì', doc.metadata.get('íŒê²°ì¼ì', ''))\n",
        "            court = doc.metadata.get('ë²•ì›ëª…', '')\n",
        "\n",
        "            reference = f\"[íŒë¡€ {i+1}] {court} {case_num} ({case_date}): {content}\"\n",
        "\n",
        "        elif doc_type == 'í•´ì„ë¡€':\n",
        "            exp_name = doc.metadata.get('ì•ˆê±´ëª…', '')\n",
        "            exp_date = doc.metadata.get('íšŒì‹ ì¼ì', '')\n",
        "\n",
        "            reference = f\"[í•´ì„ë¡€ {i+1}] {exp_name} ({exp_date}): {content}\"\n",
        "\n",
        "        else:\n",
        "            reference = f\"[ì°¸ì¡° {i+1}] {content}\"\n",
        "\n",
        "        response_prompt += reference + \"\\n\\n\"\n",
        "        final_ref.append(reference)\n",
        "\n",
        "    response_prompt += \"\"\"\n",
        "    ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”. ë‹¤ìŒ ê°€ì´ë“œë¼ì¸ì„ ë”°ë¼ì£¼ì„¸ìš”:\n",
        "    1. ë¬¸ì„œë“¤ì„ ëª…í™•íˆ ì¸ìš©í•´ì£¼ì„¸ìš” (ì˜ˆ: [ë²•ë ¹ 1]ì— ë”°ë¥´ë©´..., [íŒë¡€ 1]ì— ë”°ë¥´ë©´..., [í•´ì„ë¡€ 1]ì— ë”°ë¥´ë©´... ë“±).\n",
        "    2. ë²•ë¥  ìš©ì–´ëŠ” ì¼ë°˜ì¸ì´ ì´í•´í•  ìˆ˜ ìˆë„ë¡ í’€ì–´ì„œ ì„¤ëª…í•´ì£¼ì„¸ìš”.\n",
        "    3. ë‹µë³€ì€ ë…¼ë¦¬ì ì´ê³  ë‹¨ë½ì´ ë‚˜ëˆ ì ¸ì•¼ í•©ë‹ˆë‹¤.\n",
        "    4. ê²°ë¡ ì„ ëª…í™•íˆ ì œì‹œí•´ì£¼ì„¸ìš”.\n",
        "    \"\"\"\n",
        "\n",
        "    # LLMìœ¼ë¡œ ìµœì¢… ë‹µë³€ ìƒì„±\n",
        "    final_answer = llm.predict(response_prompt)\n",
        "    print(\"\\n=== ìµœì¢… ë‹µë³€ ===\\n\")\n",
        "    print(final_answer)\n",
        "    print(\"\\n\\n=== ì°¸ì¡° ë¬¸ì„œ ëª©ë¡ ===\\n\")\n",
        "    for i, reference in enumerate(final_ref):\n",
        "        print(f\"{reference}\\n\")\n",
        "\n",
        "    # í‰ê°€ ìˆ˜í–‰\n",
        "    ragas_llm = ChatOpenAI(model=\"gpt-4o\")\n",
        "    evaluation_dataset = EvaluationDataset.from_list([{\n",
        "        \"user_input\": query,\n",
        "        \"retrieved_contexts\": [doc.page_content for doc in filtered_docs],\n",
        "        \"response\": final_answer,\n",
        "    }])\n",
        "    evaluator_llm = LangchainLLMWrapper(ragas_llm)\n",
        "    result = evaluate(dataset=evaluation_dataset,\n",
        "                      metrics=[Faithfulness(), ResponseRelevancy()],\n",
        "                      llm=evaluator_llm)\n",
        "\n",
        "    return final_answer, final_ref, result"
      ],
      "metadata": {
        "id": "8sGKCwEngieD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "193e7545-ea3c-4c96-a6d1-f59b3ddb5a45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing generate_answer_and_evaluate.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ë‹µë³€ í•˜ì´ë¼ì´íŒ…"
      ],
      "metadata": {
        "id": "XkIqslFNTZc9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile utils.py\n",
        "import re\n",
        "\n",
        "def linkify_articles(text):\n",
        "    def replacer(match):\n",
        "        full = match.group(0)\n",
        "\n",
        "        # ì¡°ë¬¸ ë²ˆí˜¸ ì¶”ì¶œ (ex: ì œ101ì¡°ì˜ 3 â†’ 101, 3)\n",
        "        article_match = re.search(r'ì œ(\\d+)(?:ì¡°(?:ì˜\\s?(\\d+))?)?', full)\n",
        "        if not article_match:\n",
        "            return full\n",
        "\n",
        "        base_num = article_match.group(1)  # ex: '101'\n",
        "        sub_num = article_match.group(2)   # ex: '3' if 'ì˜ 3'ì´ ìˆëŠ” ê²½ìš°\n",
        "\n",
        "        # ì¡°ë¬¸ í‘œì‹œ: ì œ101ì¡° or ì œ101ì¡°ì˜ 3\n",
        "        if sub_num:\n",
        "            article_name = f\"ì œ{base_num}ì¡°ì˜{sub_num}\"\n",
        "        else:\n",
        "            article_name = f\"ì œ{base_num}ì¡°\"\n",
        "\n",
        "        # ìµœì¢… URL ìƒì„± (í•­ì€ URLì— ë°˜ì˜í•˜ì§€ ì•ŠìŒ)\n",
        "        url = f\"https://www.law.go.kr/ë²•ë ¹/ì €ì‘ê¶Œë²•/{article_name}\"\n",
        "\n",
        "        return f\"[{full}]({url})\"\n",
        "\n",
        "    # ëŒ€ìƒ ë¬¸ì¥: ì €ì‘ê¶Œë²• ì œxxì¡°(ì˜ x)? (ì œní•­)?\n",
        "    pattern = r\"(ì €ì‘ê¶Œë²• ì œ\\d+ì¡°(?:ì˜\\s?\\d+)?(?: ì œ\\d+í•­)?)\"\n",
        "    return re.sub(pattern, replacer, text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fzcN4aV7c5zw",
        "outputId": "e398d012-b679-4601-f3d5-df58e342b9f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing utils.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ì••ì¶•ê¸° + ë©€í‹°ì¿¼ë¦¬ ë¦¬íŠ¸ë¦¬ë²„ + ë¦¬ë­ì»¤ + í‰ê°€"
      ],
      "metadata": {
        "id": "gQpSKICFnYxI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile all_step.py\n",
        "import json\n",
        "from config import OPENAI_API_KEY, FAISS_INDEX_PATH\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.retrievers.document_compressors import CrossEncoderReranker\n",
        "from transformers import AutoModel\n",
        "from langchain.retrievers import ContextualCompressionRetriever\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from ragas import EvaluationDataset, evaluate\n",
        "from ragas.llms import LangchainLLMWrapper\n",
        "from ragas.metrics import Faithfulness, ResponseRelevancy\n",
        "from intent_analysis import intent_analysis\n",
        "from generate_multiquery_and_retrieve import generate_multiquery_and_retrieve\n",
        "from generate_answer_and_evaluate import generate_answer_and_evaluate\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
        "\n",
        "def all_step(query):\n",
        "    MAX_RETRIES = 3\n",
        "    retry_count = 0\n",
        "    final_result = None\n",
        "    fallback_results = []\n",
        "    FAIL_MESSAGE = \"ì£„ì†¡í•©ë‹ˆë‹¤. ì§ˆë¬¸ì— ëŒ€í•œ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì¡°ê¸ˆ ë” êµ¬ì²´ì ì¸ ìƒí™©ì„ ì¶”ê°€í•´ì„œ ì§ˆë¬¸í•´ì£¼ì„¸ìš”.\"\n",
        "    success_attempt = None\n",
        "\n",
        "    intent_result = intent_analysis(query)\n",
        "    if not intent_result['is_copyright_related']:\n",
        "        return \"ì €ì‘ê¶Œë²•ê³¼ ê´€ë ¨ëœ ì§ˆë¬¸ì„ í•´ì£¼ì„¸ìš”. ë‹¤ë¥¸ ë²•ë ¹ì— ê´€í•œ ì§ˆë¬¸ì€ ë‹µë³€í•˜ê¸° ì–´ë µìŠµë‹ˆë‹¤.\", [], None, [], \"ê¸°íƒ€\", \"ê¸°íƒ€\"\n",
        "\n",
        "    embeddings_model = OpenAIEmbeddings(\n",
        "        model=\"text-embedding-3-large\",\n",
        "        openai_api_key=OPENAI_API_KEY\n",
        "    )\n",
        "    vectorstore = FAISS.load_local(FAISS_INDEX_PATH, embeddings_model, allow_dangerous_deserialization=True)\n",
        "\n",
        "    llm = ChatOpenAI(\n",
        "        temperature=0,\n",
        "        model_name='gpt-4-turbo',\n",
        "        openai_api_key=OPENAI_API_KEY\n",
        "    )\n",
        "\n",
        "    retriever = MultiQueryRetriever.from_llm(\n",
        "        retriever=vectorstore.as_retriever(),\n",
        "        llm=llm\n",
        "    )\n",
        "\n",
        "    # âœ… ëŒ€í™” ì œëª©, ì¹´í…Œê³ ë¦¬, ê´€ë ¨ ì§ˆë¬¸ í•œ ë²ˆì— ìƒì„±\n",
        "    metadata_prompt = f\"\"\"\n",
        "    ë‹¤ìŒì€ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì…ë‹ˆë‹¤:\n",
        "\n",
        "    \"{query}\"\n",
        "\n",
        "    ì´ ì§ˆë¬¸ì— ëŒ€í•´ ë‹¤ìŒ í•­ëª©ì„ ìˆœì„œëŒ€ë¡œ ì¶œë ¥í•´ì£¼ì„¸ìš”:\n",
        "\n",
        "    1. ëŒ€í™” ì œëª© (15ì ì´ë‚´, ë”°ì˜´í‘œ ì—†ì´)\n",
        "    2. ì¹´í…Œê³ ë¦¬ (í•œ ë‹¨ì–´ë‚˜ ì§§ì€ ë¬¸ì¥)\n",
        "    3. ê´€ë ¨ëœ ì¶”ê°€ ì§ˆë¬¸ 3ê°€ì§€ (ì¤„ë°”ê¿ˆìœ¼ë¡œ êµ¬ë¶„)\n",
        "\n",
        "    ì¶œë ¥ ì˜ˆì‹œ:\n",
        "\n",
        "    ì œëª©: ìœ íŠœë¸Œ ìŒì•… ì €ì‘ê¶Œ\n",
        "    ì¹´í…Œê³ ë¦¬: ìŒì•…ì €ì‘ê¶Œ\n",
        "    ê´€ë ¨ ì§ˆë¬¸:\n",
        "    - ìœ íŠœë¸Œ ì˜ìƒì— ë°°ê²½ìŒì•…ìœ¼ë¡œ ìƒì—…ê³¡ì„ ì‚¬ìš©í•˜ë©´ ë¬¸ì œê°€ ë˜ë‚˜ìš”?\n",
        "    - ê°•ì˜ìë£Œì— ë°°ê²½ìŒì•…ì„ ì‚½ì…í•´ë„ ë˜ë‚˜ìš”?\n",
        "    - ë‹¤ë¥¸ ì‚¬ëŒì˜ ìŒì•…ì„ í¸ì§‘í•´ì„œ ì¨ë„ ë˜ë‚˜ìš”?\n",
        "    \"\"\"\n",
        "    metadata_result = llm.predict(metadata_prompt).strip()\n",
        "    lines = metadata_result.splitlines()\n",
        "    title = lines[0].replace(\"ì œëª©:\", \"\").strip()\n",
        "    category = lines[1].replace(\"ì¹´í…Œê³ ë¦¬:\", \"\").strip()\n",
        "    related_questions = [line.replace(\"- \", \"\").strip() for line in lines[3:] if line.strip()]\n",
        "\n",
        "    model = AutoModel.from_pretrained(\n",
        "        'jinaai/jina-reranker-m0',\n",
        "        torch_dtype=\"auto\",\n",
        "        trust_remote_code=True,\n",
        "        attn_implementation=\"flash_attention_2\"\n",
        "    )\n",
        "    model.to(\"cuda\")\n",
        "\n",
        "    # âœ… ë¬¸ì„œ í•„í„° ì„¤ì •\n",
        "    document_type_filters = []\n",
        "    for doc_type in intent_result['document_types']:\n",
        "        if doc_type == \"ë²•ë ¹\":\n",
        "            law_filter = {\"ë¬¸ì„œìœ í˜•\": \"ë²•ë ¹\"}\n",
        "            article_num = intent_result['specific_article'].get(\"article\")\n",
        "            ho_num = intent_result['specific_article'].get(\"ho\")\n",
        "            if article_num:\n",
        "                law_filter[\"ì¡°ë¬¸ë²ˆí˜¸\"] = f\"{article_num}ì¡°\"\n",
        "                if ho_num:\n",
        "                    law_filter[\"í˜¸ë²ˆí˜¸\"] = ho_num\n",
        "            document_type_filters.append(law_filter)\n",
        "\n",
        "        elif doc_type == \"ë¶€ì¹™\":\n",
        "            sub_filter = {\"ë¬¸ì„œìœ í˜•\": \"ë¶€ì¹™\"}\n",
        "            article_num = intent_result['specific_article'].get(\"article\")\n",
        "            if article_num:\n",
        "                sub_filter[\"ì¡°ë¬¸ë²ˆí˜¸\"] = f\"{article_num}ì¡°\"\n",
        "            document_type_filters.append(sub_filter)\n",
        "\n",
        "        elif doc_type == \"ì‹œí–‰ë ¹\":\n",
        "            ord_filter = {\"ë¬¸ì„œìœ í˜•\": \"ì‹œí–‰ë ¹\"}\n",
        "            article_num = intent_result['specific_article'].get(\"article\")\n",
        "            ho_num = intent_result['specific_article'].get(\"ho\")\n",
        "            if article_num:\n",
        "                ord_filter[\"ì¡°ë¬¸ë²ˆí˜¸\"] = f\"{article_num}ì¡°\"\n",
        "                if ho_num:\n",
        "                    ord_filter[\"í˜¸ë²ˆí˜¸\"] = ho_num\n",
        "            document_type_filters.append(ord_filter)\n",
        "\n",
        "        elif doc_type == \"íŒë¡€\":\n",
        "            case_filter = {\"ë¬¸ì„œìœ í˜•\": \"íŒë¡€\"}\n",
        "            article_num = intent_result['specific_article'].get(\"article\")\n",
        "            ho_num = intent_result['specific_article'].get(\"ho\")\n",
        "            related_article = []\n",
        "            if article_num:\n",
        "                if ho_num:\n",
        "                    related_article.append(f\"ì €ì‘ê¶Œë²• ì œ{article_num}ì¡° ì œ{ho_num}í˜¸\")\n",
        "                else:\n",
        "                    related_article.append(f\"ì €ì‘ê¶Œë²• ì œ{article_num}ì¡°\")\n",
        "            if related_article:\n",
        "                case_filter[\"ì°¸ì¡°ì¡°ë¬¸\"] = {\"$in\": related_article}\n",
        "            document_type_filters.append(case_filter)\n",
        "\n",
        "        elif doc_type == \"í•´ì„ë¡€\":\n",
        "            exp_filter = {\"ë¬¸ì„œìœ í˜•\": \"í•´ì„ë¡€\"}\n",
        "            document_type_filters.append(exp_filter)\n",
        "\n",
        "    final_filter = {\"$or\": document_type_filters} if document_type_filters else {}\n",
        "    if final_filter:\n",
        "        vectorstore.as_retriever().search_kwargs[\"filter\"] = final_filter\n",
        "\n",
        "    while retry_count < MAX_RETRIES:\n",
        "        filtered_docs = generate_multiquery_and_retrieve(query, retry_count, retriever, llm, model)\n",
        "        final_answer, final_ref, evaluation_result = generate_answer_and_evaluate(query, filtered_docs, llm)\n",
        "\n",
        "        faithfulness = evaluation_result[\"faithfulness\"][0]\n",
        "        relevancy = evaluation_result[\"answer_relevancy\"][0]\n",
        "\n",
        "        if faithfulness >= 0.5 and relevancy >= 0.7:\n",
        "            final_result = final_answer\n",
        "            success_attempt = retry_count + 1\n",
        "            break\n",
        "        elif 0.1 < faithfulness < 0.5 and relevancy >= 0.8:\n",
        "            fallback_results.append({\n",
        "                \"answer\": final_answer,\n",
        "                \"docs\": filtered_docs,\n",
        "                \"final_ref\": final_ref,\n",
        "                \"faithfulness\": faithfulness,\n",
        "                \"relevancy\": relevancy,\n",
        "                \"retry\": retry_count + 1\n",
        "            })\n",
        "\n",
        "        retry_count += 1\n",
        "\n",
        "    if final_result:\n",
        "        success_message = f\"âœ… {success_attempt}íšŒì°¨ ì‹œë„ì— ì •ì‹ ê¸°ì¤€ìœ¼ë¡œ ë‹µë³€ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.\"\n",
        "        final_result_with_note = f\"{success_message}\\n\\n{final_result}\"\n",
        "        return final_result_with_note, final_result, filtered_docs, evaluation_result, related_questions, category, title\n",
        "\n",
        "    elif fallback_results:\n",
        "        best_fallback = max(fallback_results, key=lambda x: (x[\"relevancy\"] + x[\"faithfulness\"]))\n",
        "        fallback_msg = f\"\"\"âš ï¸ ì •ì‹ ê¸°ì¤€ì€ ì¶©ì¡±í•˜ì§€ ëª»í–ˆì§€ë§Œ {best_fallback['retry']}íšŒì°¨ ì‹œë„ì— ìœ ì‚¬í•œ ë‹µë³€ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤:\\n\\n{best_fallback['answer']}\\n\\nâ€» ë” ì •í™•í•œ ë‹µë³€ì„ ì›í•˜ì‹œë©´ ì§ˆë¬¸ì„ ì¡°ê¸ˆ ë” êµ¬ì²´ì ìœ¼ë¡œ ì‘ì„±í•´ ì£¼ì„¸ìš”.\"\"\"\n",
        "        return fallback_msg, best_fallback[\"answer\"], best_fallback[\"docs\"], evaluation_result, related_questions, category, title\n",
        "\n",
        "    else:\n",
        "        return FAIL_MESSAGE, FAIL_MESSAGE, [], None, related_questions, category, title\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JRTYPEjGnZlw",
        "outputId": "8bbd63a8-b1da-44a1-a322-263c94e5735d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting all_step.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Streamlit"
      ],
      "metadata": {
        "id": "0dhrHCo4T9pO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import re\n",
        "import time\n",
        "import json\n",
        "\n",
        "import openai\n",
        "from openai import OpenAI\n",
        "from config import OPENAI_API_KEY\n",
        "from intent_analysis import intent_analysis\n",
        "from generate_multiquery_and_retrieve import generate_multiquery_and_retrieve\n",
        "from generate_answer_and_evaluate import generate_answer_and_evaluate\n",
        "from all_step import all_step\n",
        "from utils import linkify_articles\n",
        "from google_sheets import append_feedback_to_sheet\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from sentence_transformers import CrossEncoder\n",
        "\n",
        "openai.api_key = OPENAI_API_KEY\n",
        "client = OpenAI(api_key=OPENAI_API_KEY)\n",
        "\n",
        "st.set_page_config(page_title=\"ASAC ë²•ë¥ ìë¬¸ AI\", layout=\"wide\", page_icon=\"ğŸ“š\")\n",
        "st.title(\"ASAC ì €ì‘ê¶Œë²• ë²•ë¥  ìë¬¸ì— ì˜¤ì‹  ê²ƒì„ í™˜ì˜í•©ë‹ˆë‹¤.\")\n",
        "\n",
        "st.markdown(\"\"\"\n",
        "<div style='font-size:18px; line-height:1.6'>\n",
        "ì €ì‘ê¶Œë²• ì „ë¬¸ ìƒì„±í˜• AIê°€ ë²•ë ¹, íŒë¡€, í•´ì„ë¡€ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‹ ì†í•˜ê³  ì‹ ë¢°ì„± ìˆëŠ” ìë¬¸ì„ ì œê³µí•©ë‹ˆë‹¤.<br><br>\n",
        "</div>\n",
        "\"\"\", unsafe_allow_html=True)\n",
        "\n",
        "st.markdown(\"\"\"\n",
        "<div style='font-size:15px; color:#888; border:1px solid #ddd; padding:10px; border-radius:5px; margin-bottom:10px;'>\n",
        "    <div style='font-size:20px; line-height:1.6; color:#888;'><b>ğŸ“Œ ì§ˆë¬¸ ì˜ˆì‹œ</b></div>\n",
        "    <div>ã€€ã€€Q. ìœ íŠœë¸Œ ì˜ìƒì— ë‹¤ë¥¸ ì‚¬ëŒì˜ ìŒì•…ì„ ë°°ê²½ìœ¼ë¡œ ì“°ë©´ ì €ì‘ê¶Œ ì¹¨í•´ì¸ê°€ìš”?</div>\n",
        "    <div>ã€€ã€€Q. í—ˆë½ ì—†ì´ ì¨ë„ ë˜ëŠ” ì €ì‘ë¬¼ì˜ ì¡°ê±´ì— ë­ê°€ ìˆë‚˜ìš”?</div>\n",
        "    <div>ã€€ã€€Q. ìœ íŠœë¸Œì— ì˜¬ë¦¬ëŠ” ê²ƒê³¼ ê°œì¸ ë¸”ë¡œê·¸ì— ì“°ëŠ” ê²ƒ ì¤‘ ë­ê°€ ë” ë¬¸ì œì¸ê°€ìš”?</div>\n",
        "</div>\n",
        "\"\"\", unsafe_allow_html=True)\n",
        "\n",
        "# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”\n",
        "for key in [\"messages\", \"chat_sessions\", \"active_chat\", \"related_questions\", \"prompt_input\"]:\n",
        "    if key not in st.session_state:\n",
        "        st.session_state[key] = [] if key in [\"messages\", \"related_questions\"] else {} if key == \"chat_sessions\" else None\n",
        "\n",
        "# ì‚¬ì´ë“œë°”\n",
        "with st.sidebar:\n",
        "    if st.button(\"â• ìƒˆ ëŒ€í™”\"):\n",
        "        st.session_state.messages = []\n",
        "        st.session_state.active_chat = \"ëŒ€í™” ì¤€ë¹„ ì¤‘...\"\n",
        "        st.session_state.related_questions = []\n",
        "        st.session_state.prompt_input = None\n",
        "\n",
        "    st.subheader(\"ğŸ“ ì´ì „ ëŒ€í™”\")\n",
        "    for title in reversed(list(st.session_state.chat_sessions.keys())):\n",
        "        if st.button(title):\n",
        "            st.session_state.messages = st.session_state.chat_sessions[title][\"messages\"]\n",
        "            st.session_state.active_chat = title\n",
        "            st.session_state.related_questions = st.session_state.chat_sessions[title].get(\"related\", [])\n",
        "            st.session_state.prompt_input = None\n",
        "\n",
        "# ì‚¬ìš©ì ì…ë ¥\n",
        "user_input = st.chat_input(\"ì €ì‘ê¶Œë²•ì— ê´€í•œ ê¶ê¸ˆí•œ ì ì„ ì…ë ¥í•˜ì„¸ìš”.\")\n",
        "if user_input:\n",
        "    st.session_state[\"prompt_input\"] = user_input\n",
        "\n",
        "# ì§ˆë¬¸ì´ ë“¤ì–´ì˜¨ ê²½ìš° ì²˜ë¦¬\n",
        "if st.session_state[\"prompt_input\"]:\n",
        "    prompt = st.session_state[\"prompt_input\"]\n",
        "    spinner = st.empty()\n",
        "    spinner.info(\"ğŸ§  AIê°€ ì‹ ì¤‘íˆ ë‹µë³€ì„ êµ¬ì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤...\")\n",
        "\n",
        "    try:\n",
        "        final_result_with_note, final_answer, source_docs, evaluation_result, related_questions, category, title = all_step(prompt)\n",
        "        st.session_state.related_questions = related_questions\n",
        "\n",
        "        st.session_state.messages.append({\"role\": \"user\", \"content\": prompt, \"source_docs\": []})\n",
        "        st.session_state.messages.append({\n",
        "            \"role\": \"assistant\",\n",
        "            \"content\": final_result_with_note,\n",
        "            \"source_docs\": source_docs\n",
        "        })\n",
        "\n",
        "        st.session_state.active_chat = title\n",
        "        st.session_state.chat_sessions[title] = {\n",
        "            \"messages\": st.session_state.messages,\n",
        "            \"category\": category,\n",
        "            \"related\": related_questions\n",
        "        }\n",
        "\n",
        "        spinner.empty()\n",
        "\n",
        "    except Exception as e:\n",
        "        spinner.empty()\n",
        "        st.error(f\"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
        "        st.stop()\n",
        "\n",
        "    finally:\n",
        "        st.session_state[\"prompt_input\"] = None\n",
        "\n",
        "# ì±„íŒ… ë©”ì‹œì§€ ì¶œë ¥\n",
        "if st.session_state.active_chat and st.session_state.active_chat != \"ëŒ€í™” ì¤€ë¹„ ì¤‘...\":\n",
        "    category = st.session_state.chat_sessions[st.session_state.active_chat].get(\"category\", \"ê¸°íƒ€\")\n",
        "    if not category or not category.strip():\n",
        "        category = \"ê¸°íƒ€\"\n",
        "    st.markdown(f\"ğŸ“‚ **ì¹´í…Œê³ ë¦¬:** `{category}`\")\n",
        "\n",
        "    with st.container():\n",
        "        for idx, msg in enumerate(st.session_state.messages):\n",
        "            with st.chat_message(msg[\"role\"]):\n",
        "                st.markdown(linkify_articles(msg[\"content\"]), unsafe_allow_html=True)\n",
        "\n",
        "                if msg[\"role\"] == \"assistant\" and \"source_docs\" in msg:\n",
        "                    st.markdown(\"ğŸ“ **ì°¸ì¡° ë¬¸ì„œ ëª©ë¡**\")\n",
        "                    for i, doc in enumerate(msg[\"source_docs\"]):\n",
        "                        doc_type = doc.metadata.get(\"ë¬¸ì„œìœ í˜•\", \"ë¬¸ì„œ\")\n",
        "                        type_icon_map = {\n",
        "                          \"íŒë¡€\": \"ğŸ“„\",\n",
        "                          \"í•´ì„ë¡€\": \"ğŸ“˜\",\n",
        "                          \"ë²•ë ¹\": \"ğŸ“œ\",\n",
        "                          \"ì‹œí–‰ë ¹\": \"ğŸ“‘\",\n",
        "                          \"ë¶€ì¹™\": \"ğŸ“‚\",\n",
        "                        }\n",
        "                        icon = type_icon_map.get(doc_type, \"ğŸ“\")\n",
        "                        label = f\"{icon} {doc_type or 'ë¬¸ì„œ'} {i+1}\"\n",
        "                        st.write(f\"**{label}**\")\n",
        "                        st.write(doc.page_content[:300] + \"...\")\n",
        "                        visible_keys = ['ì‚¬ê±´ëª…', 'ì‚¬ê±´ë²ˆí˜¸', 'ì„ ê³ ì¼ì', 'ë²•ì›ëª…']\n",
        "                        meta = {k: v for k, v in doc.metadata.items() if k in visible_keys}\n",
        "\n",
        "                        if meta:\n",
        "                            court = meta.get('ë²•ì›ëª…', '')\n",
        "                            case_title = meta.get('ì‚¬ê±´ëª…', '')\n",
        "                            case_number = meta.get('ì‚¬ê±´ë²ˆí˜¸', '')\n",
        "                            date = meta.get('ì„ ê³ ì¼ì', '')\n",
        "\n",
        "                            summary = f\"\"\"\n",
        "                            <div style='background-color:#f9f9f9; color:green; border:1px solid #ddd; padding:10px; border-radius:5px; margin-bottom:10px;'>\n",
        "                            ğŸ“„ {date}ì— {court}ì—ì„œ '{case_title}' ì‚¬ê±´({case_number})ì— ëŒ€í•œ íŒê²°ì…ë‹ˆë‹¤.\n",
        "                            </div>\n",
        "                            \"\"\"\n",
        "                            st.markdown(summary, unsafe_allow_html=True)\n",
        "\n",
        "                if msg[\"role\"] == \"assistant\":\n",
        "                    feedback_key = f\"feedback_{idx}\"\n",
        "                    if not st.session_state.get(feedback_key):\n",
        "                        with st.expander(\"ì´ ë‹µë³€ì´ ë„ì›€ì´ ë˜ì—ˆë‚˜ìš”?\"):\n",
        "                            col1, col2, col3 = st.columns(3)\n",
        "                            with col1:\n",
        "                                if st.button(\"ğŸ‘ ë„ì›€ì´ ëì–´ìš”\", key=f\"helpful_{idx}\"):\n",
        "                                    append_feedback_to_sheet(\"ë„ì›€ì´ ëì–´ìš”\", msg[\"content\"], st.session_state.active_chat)\n",
        "                                    st.success(\"ê°ì‚¬í•©ë‹ˆë‹¤.\")\n",
        "                                    st.session_state[feedback_key] = True\n",
        "                            with col2:\n",
        "                                if st.button(\"ğŸ‘ ë” ê¶ê¸ˆí•´ìš”\", key=f\"more_info_{idx}\"):\n",
        "                                    append_feedback_to_sheet(\"ë” ê¶ê¸ˆí•´ìš”\", msg[\"content\"], st.session_state.active_chat)\n",
        "                                    st.success(\"ì¶”ê°€ ê°œì„ í•˜ê²Œì‚¬í•©ë‹ˆë‹¤.\")\n",
        "                                    st.session_state[feedback_key] = True\n",
        "                            with col3:\n",
        "                                if st.button(\"ğŸ¤” ì´í•´ê°€ ì–´ë µìŠµë‹ˆë‹¤\", key=f\"difficult_{idx}\"):\n",
        "                                    append_feedback_to_sheet(\"ì´í•´ ì–´ë µìŠµë‹ˆë‹¤\", msg[\"content\"], st.session_state.active_chat)\n",
        "                                    st.success(\"ë„ì›€ ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤.\")\n",
        "                                    st.session_state[feedback_key] = True\n",
        "\n",
        "    valid_related = [q for q in st.session_state.related_questions if q.strip()]\n",
        "    if valid_related:\n",
        "        st.markdown(\"ğŸ“š **ì¶”ê°€ë¡œ ê¶ê¸ˆí•  ìˆ˜ ìˆëŠ” ì§ˆë¬¸**\")\n",
        "        for idx, q in enumerate(valid_related[:3]):\n",
        "            if st.button(q, key=f\"related_q_{idx}\"):\n",
        "                st.session_state[\"prompt_input\"] = q\n",
        "else:\n",
        "    st.info(\"ì™¼ìª½ì—ì„œ ëŒ€í™”ë¥¼ ì„ íƒí•˜ê±°ë‚˜ ìƒˆ ëŒ€í™”ë¥¼ ì‹œì‘í•˜ì„¸ìš”.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QGsDufPkc87L",
        "outputId": "4ed3f458-34b3-446a-96e6-583249b8aa27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyngrok\n",
        "!pip install streamlit"
      ],
      "metadata": {
        "id": "zgt25RHl3PtH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28a1ce35-366e-4ce7-9526-1be719919dea",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.11/dist-packages (7.2.8)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n",
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.11/dist-packages (1.45.1)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.2.0)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (24.2)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.2.1)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.29.4)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (9.1.2)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.13.2)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.44)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.9.1)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.39.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2025.4.26)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.24.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !ngrok authtoken \"2v76lh7I7WduDxuyx8tqMtHWaPB_7zmsD78Fh8NQy9KBzfE1C\" #ë‚´êº¼1\n",
        "!ngrok authtoken \"2wWlfT7uTD4KMIX6XQGifLtZDpj_3tQ5r1nAEpwsGHnRuyEN8\" #í¬ë ¨"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZeEnMDyxvhpZ",
        "outputId": "cb58708b-a566-4966-c5c0-9ff0331b0c5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pkill -9 ngrok\n",
        "!pkill -9 streamlit"
      ],
      "metadata": {
        "id": "HzR-N5uRfi-d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "import subprocess\n",
        "\n",
        "# ê¸°ì¡´ ngrok í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ\n",
        "ngrok.kill()\n",
        "\n",
        "# Streamlit ì‹¤í–‰\n",
        "command = \"streamlit run app.py --server.port 8501 &\"\n",
        "process = subprocess.Popen(command, shell=True)\n",
        "\n",
        "# ngrok í„°ë„ ìƒì„± (í¬íŠ¸ ì„¤ì • ë³€ê²½)\n",
        "public_url = ngrok.connect(addr=\"8501\", proto=\"http\")\n",
        "print(f\"Streamlit ì•±ì´ ì‹¤í–‰ë˜ì—ˆìŠµë‹ˆë‹¤! {public_url}\")\n"
      ],
      "metadata": {
        "id": "0VgkSYPJvwfK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86b7e5ae-7016-4a98-fe60-9d8923499e1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Streamlit ì•±ì´ ì‹¤í–‰ë˜ì—ˆìŠµë‹ˆë‹¤! NgrokTunnel: \"https://5f41-34-87-124-247.ngrok-free.app\" -> \"http://localhost:8501\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "71CORkXTBQCH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}