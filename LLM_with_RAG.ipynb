{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4",
      "collapsed_sections": [
        "TP9qrcMfS8Id"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#환경 세팅"
      ],
      "metadata": {
        "id": "qt64O2ABTAT6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qN0HjNa8cRY1",
        "outputId": "0eabca1e-b6de-4fd2-d88e-30bfffaac197",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m78.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.3/31.3 MB\u001b[0m \u001b[31m68.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m111.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.0/60.0 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m105.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# requirements\n",
        "!pip install -q -U langchain langchain-community faiss-cpu tiktoken pyngrok streamlit gspread oauth2client"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q flash-attn --no-build-isolation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vI_4bzJZfSAq",
        "outputId": "84ba728b-78d5-4f1d-a4fa-c0686bbd613b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/6.0 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m191.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m107.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m121.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m97.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m57.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m41.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m108.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for flash-attn (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re"
      ],
      "metadata": {
        "id": "JU8_Al-bfUSG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_rows', None)"
      ],
      "metadata": {
        "id": "OoBPgj-vdtxd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1AnVVuyGdx3c",
        "outputId": "8454f07d-8ba6-43c7-988e-1e238b06eb5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 1-Kj768zG_e2td3uPTwsDn8C5aKzRDHpA\n",
        "!gdown 1-CWb77ho-P5j1ZZTMXG7Iey4nXaFkoAr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VAUFvUy5f-Gu",
        "outputId": "543e0c67-3bbb-435e-acae-a41b6ebfdda3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-Kj768zG_e2td3uPTwsDn8C5aKzRDHpA\n",
            "To: /content/index.pkl\n",
            "100% 15.1M/15.1M [00:00<00:00, 15.4MB/s]\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1-CWb77ho-P5j1ZZTMXG7Iey4nXaFkoAr\n",
            "From (redirected): https://drive.google.com/uc?id=1-CWb77ho-P5j1ZZTMXG7Iey4nXaFkoAr&confirm=t&uuid=396f6ce6-21d5-41c6-9e1c-de02291b8d71\n",
            "To: /content/index.faiss\n",
            "100% 217M/217M [00:04<00:00, 53.8MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir faiss_index_path"
      ],
      "metadata": {
        "id": "BhhQLpj2hIfO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "try:\n",
        "  shutil.move('/content/index.faiss','/content/faiss_index_path')\n",
        "  shutil.move('/content/index.pkl','/content/faiss_index_path')\n",
        "except:\n",
        "  pass"
      ],
      "metadata": {
        "id": "Twly1lARhaNq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile config.py\n",
        "OPENAI_API_KEY = \"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\"\n",
        "FAISS_INDEX_PATH = \"/content/faiss_index_path\"\n",
        "# CSV_PATH = \"/content/저작권법 조문.csv\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dEzalgY7cYwj",
        "outputId": "496d5b5c-da6f-463a-e994-09395ba29ffe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing config.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#피드백 저장 - Google Sheet"
      ],
      "metadata": {
        "id": "TP9qrcMfS8Id"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 1beWJlnc92f3MOp_i1XSJU6AvJVomeHvr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35963815-ceed-468d-9249-ff369627507b",
        "id": "TQeSpk93TNfg"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1beWJlnc92f3MOp_i1XSJU6AvJVomeHvr\n",
            "To: /content/credentials.json\n",
            "\r  0% 0.00/2.35k [00:00<?, ?B/s]\r100% 2.35k/2.35k [00:00<00:00, 10.9MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile google_sheets.py\n",
        "import gspread\n",
        "from oauth2client.service_account import ServiceAccountCredentials\n",
        "from datetime import datetime\n",
        "\n",
        "def append_feedback_to_sheet(feedback_type, content, chat_title):\n",
        "    # ✅ 구글 API 접근 범위 설정\n",
        "    scope = ['https://spreadsheets.google.com/feeds', 'https://www.googleapis.com/auth/drive']\n",
        "\n",
        "    # ✅ credentials.json은 동일 디렉토리에 있어야 함\n",
        "    creds = ServiceAccountCredentials.from_json_keyfile_name(\"credentials.json\", scope)\n",
        "    client = gspread.authorize(creds)\n",
        "\n",
        "    # ✅ 실제 시트 ID로 시트 열기\n",
        "    sheet_id = \"1KSPtZZagGFh-voSnLKImkpNYoJeNc8CBGhj_MrXt4QM\"\n",
        "    sheet = client.open_by_key(sheet_id).sheet1  # 첫 번째 시트 사용\n",
        "\n",
        "    # ✅ 현재 시간과 함께 한 행 삽입\n",
        "    now = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "    sheet.append_row([now, chat_title, feedback_type, content])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88d7120c-e9c6-4171-b192-a8236a87d770",
        "id": "a6BDQHD6TNfg"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing google_sheets.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#의도 파악 (프롬프트 수정)"
      ],
      "metadata": {
        "id": "qtLstNTkfsLI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile intent_analysis.py\n",
        "import re\n",
        "import json\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from sentence_transformers import CrossEncoder\n",
        "\n",
        "def intent_analysis(user_input):\n",
        "    # 사용자 질문\n",
        "    # query = user_input\n",
        "    query = \"다른사람의 저작물을 내가 거짓으로 등록하면 어떻게 되나요?\"\n",
        "    # query = \"갑은 고등학교 음악선생님인데, 학교 수업시간에 음악이론을 설명하기 위해서 공표되어 있는 노래를 저작자의 허락없이 학생들에게 들려주는 것이 저작권법위반인지?\"\n",
        "\n",
        "    # LLM 초기화\n",
        "    llm = ChatOpenAI(\n",
        "          temperature=0,\n",
        "          model_name = 'gpt-4-turbo',\n",
        "          openai_api_key='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'\n",
        "    )\n",
        "\n",
        "    # 사용자 질문 의도 파악 ########################## 수정 (5,6번 제거, 시행령 추가)\n",
        "    intent_analysis_prompt = f\"\"\"\n",
        "    분석 대상 질문: {query}\n",
        "\n",
        "    이 질문에 대해 다음을 분석해주세요:\n",
        "    1. 이 질문이 저작권법에 관한 것인지? (예/아니오)\n",
        "    2. 질문이 묻는 주요 문서 유형은 무엇인지? (법령/판례/해석례/복합적)\n",
        "    3. 특정 조문이나 호를 언급하는지? 언급한다면 어떤 조와 호인지?\n",
        "    4. 맥락적 설명이 필요한 질문인지? (개념 설명, 차이점 설명 등을 요구하는지)\n",
        "\n",
        "    각 항목에 대해 간결하게 답변하고, JSON 형식으로 응답해주세요:\n",
        "\n",
        "    ```json\n",
        "    {{\n",
        "    \"is_copyright_related\": true/false,\n",
        "    \"document_types\": [\"법령\", \"판례\", \"해석례\", \"시행령\"],\n",
        "    \"specific_article\": {{\"article\": \"조번호\", \"ho\": \"호번호\"}},\n",
        "    \"needs_context\": true/false\n",
        "    }}\n",
        "    \"\"\"\n",
        "\n",
        "    intent_analysis_result = llm.predict(intent_analysis_prompt)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # JSON 문자열을 파이썬 딕셔너리로 변환\n",
        "    try:\n",
        "        # JSON 블록 추출을 위한 정규식 (불필요한 마크다운 문법 제거)\n",
        "        json_str = re.sub(r'```.*?\\n|```', '', intent_analysis_result.strip())\n",
        "        intent_data = json.loads(json_str)\n",
        "\n",
        "    except json.JSONDecodeError:\n",
        "        # JSON 파싱 실패 시 기본값 설정\n",
        "        intent_data = {\n",
        "            \"is_copyright_related\": True,\n",
        "            \"document_types\": [\"법령\", \"판례\", \"시행령\"], ################# 수정 (시행령 추가)\n",
        "            \"specific_article\": {\"article\": \"2\", \"ho\": \"8\"},\n",
        "            \"needs_context\": True\n",
        "        }\n",
        "\n",
        "    # 분석 결과 추출\n",
        "    is_copyright_related = intent_data.get(\"is_copyright_related\", True)\n",
        "    document_types = intent_data.get(\"document_types\", [\"법령\", \"판례\", \"시행령\"])\n",
        "    specific_article = intent_data.get(\"specific_article\", {\"article\": \"2\", \"ho\": \"8\"})\n",
        "    needs_context = intent_data.get(\"needs_context\", True)\n",
        "\n",
        "    return {\n",
        "        \"is_copyright_related\": is_copyright_related,\n",
        "        \"document_types\": document_types,\n",
        "        \"specific_article\": specific_article,\n",
        "        \"needs_context\": needs_context\n",
        "    }"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q3jXAKv_fwP1",
        "outputId": "ad354f28-ca41-4c91-e422-c3dfebea909a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing intent_analysis.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#리트리버 (프롬프트 수정)"
      ],
      "metadata": {
        "id": "0NDiedgtTVyU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# %%writefile generate_multiquery_and_retrieve.py\n",
        "# from langchain.prompts import PromptTemplate\n",
        "# from langchain.retrievers.multi_query import MultiQueryRetriever\n",
        "# from langchain.retrievers.contextual_compression import ContextualCompressionRetriever  # (필요 시)\n",
        "# from langchain.chat_models import ChatOpenAI\n",
        "# from transformers import AutoModel\n",
        "# from intent_analysis import intent_analysis\n",
        "\n",
        "# def generate_multiquery_and_retrieve(query, retry_num, retriever, llm, model):\n",
        "#     intent_result = intent_analysis(query)\n",
        "#     # retry_num에 따른 다양한 프롬프트 구성##################################### (수정: needs_context 추가 및 프롬프트 수정)\n",
        "\n",
        "#     if intent_result['needs_context'] and retry_num == 0:\n",
        "#         prompt_template = f\"\"\"\n",
        "#         사용자 질문: {query}\n",
        "\n",
        "#         이 질문은 법률적 개념에 대한 맥락적 설명이 필요합니다.\n",
        "#         따라서 이 질문과 의미는 같지만 다른 표현으로 검색할 수 있는 3가지 다른 질문을 생성해주세요.\n",
        "#         다음과 같은 다양한 관점에서 질문을 작성해주세요:\n",
        "#         1. 법령 검색에 최적화된 질문\n",
        "#         2. 판례 검색에 최적화된 질문\n",
        "#         3. 법률 해석 검색에 최적화된 질문\n",
        "\n",
        "#         질문 목록만 줄바꿈으로 구분하여 작성해주세요.\n",
        "#         \"\"\"\n",
        "#     elif intent_result['needs_context'] and retry_num == 1:\n",
        "#         prompt_template = f\"\"\"\n",
        "#         아래 질문에 대한 맥락적 설명을 위해 더 다양한 키워드와 시각으로 재해석하여 검색 쿼리를 생성해주세요:\n",
        "#         {query}\n",
        "\n",
        "#         - 법률적 키워드 및 동의어를 포함해주세요.\n",
        "#         - 질문의 맥락을 확장하거나 변형하여 검색에 도움이 되도록 바꿔주세요.\n",
        "\n",
        "#         3개의 질문을 줄바꿈으로 구분해주세요.\n",
        "#         \"\"\"\n",
        "#     elif retry_num == 2:\n",
        "#         prompt_template = f\"\"\"\n",
        "#         아래 질문에 대해 다양한 시나리오를 상상하며 검색에 도움이 되는 쿼리를 생성해주세요:\n",
        "#         {query}\n",
        "\n",
        "#         - 판례, 해석례, 법령 등에서 유사 상황을 떠올리며 질문을 구성해주세요.\n",
        "#         - 의미는 유지하되 표현은 새롭게 구성해주세요.\n",
        "\n",
        "#         줄바꿈으로 구분된 3개의 질문만 작성해주세요.\n",
        "#         \"\"\"\n",
        "#     else:\n",
        "#         prompt_template = f\"{query}\"\n",
        "\n",
        "#     # 멀티쿼리 생성\n",
        "#     new_queries = llm.predict(prompt_template).strip().split('\\n')\n",
        "#     new_queries = [q.strip() for q in new_queries if q.strip()]\n",
        "#     # print(f\"\\n[멀티쿼리 {retry_num+1}회차 생성 결과] {new_queries}\")\n",
        "\n",
        "#     # 멀티쿼리 리트리버 구성\n",
        "#     prompt_obj = PromptTemplate.from_template(prompt_template)\n",
        "#     multiquery_retriever = MultiQueryRetriever.from_llm(\n",
        "#         retriever=retriever,\n",
        "#         llm=llm,\n",
        "#         prompt=prompt_obj\n",
        "#     )\n",
        "\n",
        "#     # 리랭킹\n",
        "#     docs = multiquery_retriever.invoke(query)\n",
        "#     text_pairs = [[query, doc.page_content] for doc in docs]\n",
        "#     scores = model.compute_score(text_pairs, doc_type=\"text\")\n",
        "\n",
        "#     # 점수와 docs 묶기\n",
        "#     scored_docs = list(zip(scores, docs))\n",
        "\n",
        "#     # 점수 기준 내림차순 정렬 후 상위 3개 설정\n",
        "#     top_k = sorted(scored_docs, key=lambda x: x[0], reverse=True)[:3]\n",
        "\n",
        "#     # 중복 문서 필터링\n",
        "#     filtered_docs = []\n",
        "#     seen_contents = set()\n",
        "\n",
        "#     # print(\"\\n=== 중복 문서 필터링 ===\")\n",
        "#     # print(f\"필터링 전 문서 수: {len(top_k)}\")\n",
        "#     for score, doc in top_k:\n",
        "#         # 문서 내용 정제 (간단한 방식으로)\n",
        "#         # 공백 및 특수문자 제거하고 소문자화하여 비교\n",
        "#         content = doc.page_content\n",
        "\n",
        "#         # 텍스트 정제 (비교를 위한 간소화)\n",
        "#         simplified_content = ''.join(char.lower() for char in content if char.isalnum())\n",
        "\n",
        "#         # 문서 내용 중 일부만 사용하여 중복 판단 (처음 300자) ########################## 수정 (100자->300자)\n",
        "#         content_key = simplified_content[:300]\n",
        "\n",
        "#         # 이미 비슷한 내용의 문서가 포함되었는지 확인\n",
        "#         if content_key not in seen_contents:\n",
        "#             filtered_docs.append(doc)\n",
        "#             seen_contents.add(content_key)\n",
        "\n",
        "#     # print(f\"📄 필터링 후 문서 수: {len(filtered_docs)}\")\n",
        "#     return filtered_docs"
      ],
      "metadata": {
        "id": "wKRB3yVuhEbW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df18b269-7265-4ae1-ceaa-ba7d4562f4f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing generate_multiquery_and_retrieve.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile generate_multiquery_and_retrieve.py\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
        "from langchain.retrievers.contextual_compression import ContextualCompressionRetriever  # (필요 시)\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from transformers import AutoModel\n",
        "from intent_analysis import intent_analysis\n",
        "import re\n",
        "\n",
        "def generate_multiquery_and_retrieve(query, retry_num, retriever, llm, model):\n",
        "    intent_result = intent_analysis(query)\n",
        "    # retry_num에 따른 다양한 프롬프트 구성##################################### (수정: needs_context 추가 및 프롬프트 수정)\n",
        "\n",
        "    if intent_result['needs_context'] and retry_num == 0:\n",
        "        prompt_template = f\"\"\"\n",
        "        사용자 질문: {query}\n",
        "\n",
        "        이 질문은 법률적 개념에 대한 맥락적 설명이 필요합니다.\n",
        "        따라서 이 질문과 의미는 같지만 다른 표현으로 검색할 수 있는 3가지 다른 질문을 생성해주세요.\n",
        "        다음과 같은 다양한 관점에서 질문을 작성해주세요:\n",
        "        1. 법령 검색에 최적화된 질문\n",
        "        2. 판례 검색에 최적화된 질문\n",
        "        3. 법률 해석 검색에 최적화된 질문\n",
        "\n",
        "        질문 목록만 줄바꿈으로 구분하여 작성해주세요.\n",
        "        \"\"\"\n",
        "    elif intent_result['needs_context'] and retry_num == 1:\n",
        "        prompt_template = f\"\"\"\n",
        "        아래 질문에 대한 맥락적 설명을 위해 더 다양한 키워드와 시각으로 재해석하여 검색 쿼리를 생성해주세요:\n",
        "        {query}\n",
        "\n",
        "        - 법률적 키워드 및 동의어를 포함해주세요.\n",
        "        - 질문의 맥락을 확장하거나 변형하여 검색에 도움이 되도록 바꿔주세요.\n",
        "\n",
        "        3개의 질문을 줄바꿈으로 구분해주세요.\n",
        "        \"\"\"\n",
        "    elif retry_num == 2:\n",
        "        prompt_template = f\"\"\"\n",
        "        아래 질문에 대해 다양한 시나리오를 상상하며 검색에 도움이 되는 쿼리를 생성해주세요:\n",
        "        {query}\n",
        "\n",
        "        - 판례, 해석례, 법령 등에서 유사 상황을 떠올리며 질문을 구성해주세요.\n",
        "        - 의미는 유지하되 표현은 새롭게 구성해주세요.\n",
        "\n",
        "        줄바꿈으로 구분된 3개의 질문만 작성해주세요.\n",
        "        \"\"\"\n",
        "    else:\n",
        "        prompt_template = f\"{query}\"\n",
        "\n",
        "    # 멀티쿼리 생성\n",
        "    new_queries = llm.predict(prompt_template).strip().split('\\n')\n",
        "    new_queries = [q.strip() for q in new_queries if q.strip()]\n",
        "    # print(f\"\\n[멀티쿼리 {retry_num+1}회차 생성 결과] {new_queries}\")\n",
        "\n",
        "    # 멀티쿼리 리트리버 구성\n",
        "    prompt_obj = PromptTemplate.from_template(prompt_template)\n",
        "    multiquery_retriever = MultiQueryRetriever.from_llm(\n",
        "        retriever=retriever,\n",
        "        llm=llm,\n",
        "        prompt=prompt_obj\n",
        "    )\n",
        "\n",
        "    # 리랭킹\n",
        "    docs = multiquery_retriever.invoke(query)\n",
        "    text_pairs = [[query, doc.page_content] for doc in docs]\n",
        "    scores = model.compute_score(text_pairs, doc_type=\"text\")\n",
        "\n",
        "    # 점수와 docs 묶기\n",
        "    scored_docs = list(zip(scores, docs))\n",
        "\n",
        "    # 점수 기준 내림차순 정렬 후 상위 3개 설정\n",
        "    top_k = sorted(scored_docs, key=lambda x: x[0], reverse=True)[:3]\n",
        "\n",
        "    # 중복 문서 필터링\n",
        "    filtered_docs = []\n",
        "\n",
        "    # print(\"\\n=== 간단한 중복 문서 필터링 ===\")\n",
        "    # print(f\"필터링 전 문서 수: {len(top_k)}\")\n",
        "\n",
        "    for i, (score, doc) in enumerate(top_k):\n",
        "        content = doc.page_content\n",
        "        is_duplicate = False\n",
        "\n",
        "        for j, existing_doc in enumerate(filtered_docs):\n",
        "            existing_content = existing_doc.page_content\n",
        "\n",
        "            # 핵심 키워드들을 추출하여 비교 (3글자 이상 한글 단어)\n",
        "            current_keywords = set(re.findall(r'[가-힣]{3,}', content))\n",
        "            existing_keywords = set(re.findall(r'[가-힣]{3,}', existing_content))\n",
        "\n",
        "            # Jaccard 유사도 계산 (교집합/합집합)\n",
        "            if current_keywords and existing_keywords:\n",
        "                intersection = current_keywords.intersection(existing_keywords)\n",
        "                union = current_keywords.union(existing_keywords)\n",
        "                jaccard_similarity = len(intersection) / len(union)\n",
        "\n",
        "                print(f\"문서 {i+1} vs 기존 문서 {j+1}: Jaccard 유사도 = {jaccard_similarity:.3f}\")\n",
        "\n",
        "                # 70% 이상 유사하면 중복으로 판단\n",
        "                if jaccard_similarity > 0.7:\n",
        "                    is_duplicate = True\n",
        "                    print(f\"  → 중복으로 판단됨!\")\n",
        "                    break\n",
        "\n",
        "        if not is_duplicate:\n",
        "            filtered_docs.append(doc)\n",
        "            # print(f\"문서 {len(filtered_docs)} 추가: {content[:50]}...\")\n",
        "        # else:\n",
        "            # print(f\"중복 문서 제외: {content[:50]}...\")\n",
        "    return filtered_docs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "812c390c-393f-4b5d-d636-363e4ec3ab9d",
        "id": "8jTNNLPFEhHT"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting generate_multiquery_and_retrieve.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#평가 (함수 수정)"
      ],
      "metadata": {
        "id": "O3pk-7nfgOqQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q ragas"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RwtuWl5_gP-Y",
        "outputId": "41b6ca1a-e87a-4018-896c-0723f8f989ea",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/190.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.9/190.9 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/45.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/63.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.4/63.4 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/438.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m438.3/438.3 kB\u001b[0m \u001b[31m38.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile generate_answer_and_evaluate.py\n",
        "import os\n",
        "import re\n",
        "import json\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from ragas import EvaluationDataset, evaluate\n",
        "from ragas.llms import LangchainLLMWrapper\n",
        "from ragas.metrics import Faithfulness, ResponseRelevancy\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
        "\n",
        "ragas_llm = ChatOpenAI(model=\"gpt-4o\")\n",
        "ragas_embeddings = OpenAIEmbeddings()\n",
        "\n",
        "def generate_answer_and_evaluate(query, filtered_docs, llm): ################################ 수정 (함수 전체적으로 수정- 문서 처리)\n",
        "    # 프롬프트 구성\n",
        "    final_ref = []\n",
        "    response_prompt = f\"다음은 '{query}'에 대한 관련 정보입니다:\\n\\n\"\n",
        "\n",
        "    # 중복이 제거된 문서들을 프롬프트에 추가\n",
        "    for i, doc in enumerate(filtered_docs):\n",
        "        doc_type = doc.metadata.get('문서유형', '')\n",
        "\n",
        "        # 문서 내용 가져오기\n",
        "        content = doc.page_content\n",
        "\n",
        "        # 미완성 문장 처리 (여러 패턴 대응)\n",
        "\n",
        "        # 괄호 밸런스 확인 및 수정\n",
        "        def fix_unbalanced_parentheses(text):\n",
        "            # 열린 괄호와 닫힌 괄호 개수 확인\n",
        "            open_count = text.count('(')\n",
        "            close_count = text.count(')')\n",
        "\n",
        "            # 괄호 불균형 확인\n",
        "            if open_count > close_count:\n",
        "                # 열린 괄호가 더 많은 경우, 마지막 완전한 괄호 구문 이후 내용 제거\n",
        "                # 가장 마지막 닫힌 괄호 위치 찾기\n",
        "                last_close_idx = text.rfind(')')\n",
        "                if last_close_idx > 0:\n",
        "                    # 해당 닫힌 괄호와 짝을 이루는 열린 괄호 찾기 시도\n",
        "                    stack = []\n",
        "                    for idx, char in enumerate(text[:last_close_idx+1]):\n",
        "                        if char == '(':\n",
        "                            stack.append(idx)\n",
        "                        elif char == ')':\n",
        "                            if stack:  # 짝이 맞는 열린 괄호가 있으면 pop\n",
        "                                stack.pop()\n",
        "                            # 스택이 비어있으면 짝이 안 맞는 닫힌 괄호\n",
        "\n",
        "                    # 아직 짝이 없는 열린 괄호가 있는 경우\n",
        "                    if stack:\n",
        "                        # 가장 마지막 짝이 맞는 괄호 구조 이후 위치 찾기\n",
        "                        pos = last_close_idx + 1\n",
        "                        # 불완전한 구문을 제거하고 중략 표시 추가\n",
        "                        return text[:pos] + \"...(후략)\"\n",
        "\n",
        "            # 닫힌 괄호가 더 많은 경우, 첫 번째 닫힌 괄호 위치 전까지만 사용\n",
        "            elif close_count > open_count:\n",
        "                first_unmatched_close = -1\n",
        "                stack = []\n",
        "                for idx, char in enumerate(text):\n",
        "                    if char == '(':\n",
        "                        stack.append(idx)\n",
        "                    elif char == ')':\n",
        "                        if stack:  # 짝이 맞는 열린 괄호가 있으면 pop\n",
        "                            stack.pop()\n",
        "                        else:  # 짝이 없는 첫 번째 닫힌 괄호 찾기\n",
        "                            first_unmatched_close = idx\n",
        "                            break\n",
        "\n",
        "                if first_unmatched_close > 0:\n",
        "                    return \"(전략)... \" + text[first_unmatched_close+1:]\n",
        "\n",
        "            # 괄호가 균형을 이루거나 수정이 필요없는 경우\n",
        "            return text\n",
        "\n",
        "        # 판례 인용 패턴 처리\n",
        "        def fix_case_citation(text):\n",
        "            # \"선고 OO다OO 판결 참조), \" 패턴 찾기\n",
        "            pattern = r'선고\\s+\\d+\\s*다\\s*\\d+\\s*판결\\s*참조\\)\\s*,'\n",
        "            match = re.search(pattern, text)\n",
        "            if match:\n",
        "                # 매치된 부분의 끝 위치\n",
        "                end_pos = match.end()\n",
        "                # 앞부분은 유지하고 패턴 이후의 내용은 중략 표시로 대체\n",
        "                return text[:end_pos] + \" ...(중략)\"\n",
        "            return text\n",
        "\n",
        "        #### 미완성 문장 처리 (여러 패턴 대응) ###\n",
        "\n",
        "        # 판례 인용 패턴 처리\n",
        "        content = fix_case_citation(content)\n",
        "\n",
        "        # 괄호 밸런스 확인 및 수정\n",
        "        content = fix_unbalanced_parentheses(content)\n",
        "\n",
        "        # 내용이 쉼표(,)로 시작하는 경우 처리\n",
        "        if content.strip().startswith(','):\n",
        "            content = \"...(중략) \" + content.strip()[1:].strip()\n",
        "\n",
        "        # 문장이 특정 패턴으로 시작하는 경우\n",
        "        if content.startswith('.') or content.startswith(')') or re.match(r'^\\s*[0-9]+\\.', content):\n",
        "            content = re.sub(r'^\\.\\s*', '', content)\n",
        "\n",
        "        # 미완성 문장이 끝나는 경우\n",
        "        if content.endswith('(') or content.endswith(',') or re.search(r'[a-zA-Z가-힣]\\s*$', content):\n",
        "            content = content.strip() + \"...\"\n",
        "\n",
        "        # 기존 코드의 미완성 문장 처리 (점으로 시작하는 경우)\n",
        "        if content.startswith('.'):\n",
        "            content = re.sub(r'^\\.\\s*[^.]*\\)\\s*', '', content)\n",
        "\n",
        "        # 콜론(:) 다음에 콤마(,)가 오는 경우 처리\n",
        "        content = re.sub(r':\\s*,\\s*', '', content)\n",
        "\n",
        "        # 문장이 \"이\" 또는 \"화\"와 같은 한글 한 글자로 끝나는 경우 (잘린 문장)\n",
        "        if re.search(r'[가-힣]\\s*$', content) and len(content.strip()) > 0:\n",
        "            last_char = content.strip()[-1]\n",
        "            # 문장 종결 조사가 아닌 경우에만 처리\n",
        "            if last_char not in ['다', '까', '요', '죠', '잖', '죠', '네', '요', '임']:\n",
        "                # 마지막 완전한 문장 찾기\n",
        "                last_sentence_end = max(content.rfind('. '), content.rfind('.\\n'), content.rfind('? '), content.rfind('! '))\n",
        "                if last_sentence_end > 0:\n",
        "                    # 마지막 완전한 문장까지만 유지하고 나머지는 제거\n",
        "                    content = content[:last_sentence_end+1] + \" ...(후략)\"\n",
        "                else:\n",
        "                    # 완전한 문장 구분이 없으면 그대로 ... 추가\n",
        "                    content = content.strip() + \"...\"\n",
        "\n",
        "        # 특정 판례 인용 패턴 처리 (예: \"7. 12. 선고 77다90 판결 참조),\")\n",
        "        pattern = r'\\d+\\.\\s*\\d+\\.\\s*선고\\s+\\d+다\\d+\\s*판결\\s*참조\\)\\s*,\\s*'\n",
        "        if re.search(pattern, content):\n",
        "            match = re.search(pattern, content)\n",
        "            if match:\n",
        "                end_pos = match.end()\n",
        "                if end_pos < len(content):\n",
        "                    # 패턴 이후 내용이 한 문장 이상인 경우에만 중략 처리\n",
        "                    sentences_after = re.split(r'[.!?]\\s+', content[end_pos:])\n",
        "                    if len(sentences_after) > 1 and len(sentences_after[0]) > 20:\n",
        "                        content = content[:end_pos] + \"...(이하 생략)\"\n",
        "\n",
        "        # 맨 앞에 숫자 하나만 있는 경우 처리\n",
        "        content = re.sub(r'^\\s*(\\d+)\\s+', '', content)\n",
        "\n",
        "        # 빈 문장이나 특수문자만 있는 문장 필터링\n",
        "        content = content.strip()\n",
        "        if not content or content in ['.', ',', ')', '(']:\n",
        "            continue\n",
        "\n",
        "        # 문서 유형에 따른 참조 형식 생성 ################################################# 수정(부칙, 시행령, 해석례 처리 안됐던 부분 수정)\n",
        "        if doc_type == '법령':\n",
        "            article_num = doc.metadata.get('조문번호', '')\n",
        "            article_title = doc.metadata.get('조문제목', '')\n",
        "            ho_num = doc.metadata.get('호번호', '')\n",
        "\n",
        "            if ho_num:\n",
        "                reference = f\"[법령 {i+1}] 저작권법 제{article_num} {article_title} 제{ho_num}호: {content}\"\n",
        "            else:\n",
        "                reference = f\"[법령 {i+1}] 저작권법 제{article_num} {article_title}: {content}\"\n",
        "\n",
        "        elif doc_type == '시행령':\n",
        "            ord_num = doc.metadata.get('시행령_조문번호', '')\n",
        "            ord_title = doc.metadata.get('시행령_조문제목', '')\n",
        "            ord_ho_num = doc.metadata.get('호번호', '')\n",
        "\n",
        "            if ord_ho_num:  # 'ho_num'이 아닌 'ord_ho_num' 사용 (변수명 수정)\n",
        "                reference = f\"[법령 {i+1}] 저작권법 시행령 제{ord_num} {ord_title} 제{ord_ho_num}호: {content}\"\n",
        "            else:\n",
        "                reference = f\"[법령 {i+1}] 저작권법 시행령 제{ord_num} {ord_title}: {content}\"\n",
        "\n",
        "        elif doc_type == '부칙':\n",
        "            sub_num = doc.metadata.get('부칙_조문번호', '')\n",
        "            sub_title = doc.metadata.get('부칙_조문제목', '')\n",
        "            hang_num = doc.metadata.get('항번호', '')\n",
        "\n",
        "            if hang_num:  # 'ho_num'이 아닌 'hang_num' 사용 (변수명 수정)\n",
        "                reference = f\"[법령 {i+1}] 저작권법 부칙 제{sub_num} {sub_title} 제{hang_num}호: {content}\"\n",
        "            else:\n",
        "                reference = f\"[법령 {i+1}] 저작권법 부칙 제{sub_num} {sub_title}: {content}\"\n",
        "\n",
        "        elif doc_type == '판례':\n",
        "            case_num = doc.metadata.get('사건번호', doc.metadata.get('판례번호', ''))\n",
        "            case_date = doc.metadata.get('선고일자', doc.metadata.get('판결일자', ''))\n",
        "            court = doc.metadata.get('법원명', '')\n",
        "\n",
        "            reference = f\"[판례 {i+1}] {court} {case_num} ({case_date}): {content}\"\n",
        "\n",
        "        elif doc_type == '해석례':\n",
        "            exp_name = doc.metadata.get('안건명', '')\n",
        "            exp_date = doc.metadata.get('회신일자', '')\n",
        "\n",
        "            reference = f\"[해석례 {i+1}] {exp_name} ({exp_date}): {content}\"\n",
        "\n",
        "        else:\n",
        "            reference = f\"[참조 {i+1}] {content}\"\n",
        "\n",
        "        response_prompt += reference + \"\\n\\n\"\n",
        "        final_ref.append(reference)\n",
        "\n",
        "    response_prompt += \"\"\"\n",
        "    위 정보를 바탕으로 사용자의 질문에 답변해주세요. 다음 가이드라인을 따라주세요:\n",
        "    1. 문서들을 명확히 인용해주세요 (예: [법령 1]에 따르면..., [판례 1]에 따르면..., [해석례 1]에 따르면... 등).\n",
        "    2. 법률 용어는 일반인이 이해할 수 있도록 풀어서 설명해주세요.\n",
        "    3. 답변은 논리적이고 단락이 나눠져야 합니다.\n",
        "    4. 결론을 명확히 제시해주세요.\n",
        "    \"\"\"\n",
        "\n",
        "    # LLM으로 최종 답변 생성\n",
        "    final_answer = llm.predict(response_prompt)\n",
        "    print(\"\\n=== 최종 답변 ===\\n\")\n",
        "    print(final_answer)\n",
        "    print(\"\\n\\n=== 참조 문서 목록 ===\\n\")\n",
        "    for i, reference in enumerate(final_ref):\n",
        "        print(f\"{reference}\\n\")\n",
        "\n",
        "    # 평가 수행\n",
        "    ragas_llm = ChatOpenAI(model=\"gpt-4o\")\n",
        "    evaluation_dataset = EvaluationDataset.from_list([{\n",
        "        \"user_input\": query,\n",
        "        \"retrieved_contexts\": [doc.page_content for doc in filtered_docs],\n",
        "        \"response\": final_answer,\n",
        "    }])\n",
        "    evaluator_llm = LangchainLLMWrapper(ragas_llm)\n",
        "    result = evaluate(dataset=evaluation_dataset,\n",
        "                      metrics=[Faithfulness(), ResponseRelevancy()],\n",
        "                      llm=evaluator_llm)\n",
        "\n",
        "    return final_answer, final_ref, result"
      ],
      "metadata": {
        "id": "8sGKCwEngieD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "193e7545-ea3c-4c96-a6d1-f59b3ddb5a45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing generate_answer_and_evaluate.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#답변 하이라이팅"
      ],
      "metadata": {
        "id": "XkIqslFNTZc9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile utils.py\n",
        "import re\n",
        "\n",
        "def linkify_articles(text):\n",
        "    def replacer(match):\n",
        "        full = match.group(0)\n",
        "\n",
        "        # 조문 번호 추출 (ex: 제101조의 3 → 101, 3)\n",
        "        article_match = re.search(r'제(\\d+)(?:조(?:의\\s?(\\d+))?)?', full)\n",
        "        if not article_match:\n",
        "            return full\n",
        "\n",
        "        base_num = article_match.group(1)  # ex: '101'\n",
        "        sub_num = article_match.group(2)   # ex: '3' if '의 3'이 있는 경우\n",
        "\n",
        "        # 조문 표시: 제101조 or 제101조의 3\n",
        "        if sub_num:\n",
        "            article_name = f\"제{base_num}조의{sub_num}\"\n",
        "        else:\n",
        "            article_name = f\"제{base_num}조\"\n",
        "\n",
        "        # 최종 URL 생성 (항은 URL에 반영하지 않음)\n",
        "        url = f\"https://www.law.go.kr/법령/저작권법/{article_name}\"\n",
        "\n",
        "        return f\"[{full}]({url})\"\n",
        "\n",
        "    # 대상 문장: 저작권법 제xx조(의 x)? (제n항)?\n",
        "    pattern = r\"(저작권법 제\\d+조(?:의\\s?\\d+)?(?: 제\\d+항)?)\"\n",
        "    return re.sub(pattern, replacer, text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fzcN4aV7c5zw",
        "outputId": "e398d012-b679-4601-f3d5-df58e342b9f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing utils.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#압축기 + 멀티쿼리 리트리버 + 리랭커 + 평가"
      ],
      "metadata": {
        "id": "gQpSKICFnYxI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile all_step.py\n",
        "import json\n",
        "from config import OPENAI_API_KEY, FAISS_INDEX_PATH\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.retrievers.document_compressors import CrossEncoderReranker\n",
        "from transformers import AutoModel\n",
        "from langchain.retrievers import ContextualCompressionRetriever\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from ragas import EvaluationDataset, evaluate\n",
        "from ragas.llms import LangchainLLMWrapper\n",
        "from ragas.metrics import Faithfulness, ResponseRelevancy\n",
        "from intent_analysis import intent_analysis\n",
        "from generate_multiquery_and_retrieve import generate_multiquery_and_retrieve\n",
        "from generate_answer_and_evaluate import generate_answer_and_evaluate\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
        "\n",
        "def all_step(query):\n",
        "    MAX_RETRIES = 3\n",
        "    retry_count = 0\n",
        "    final_result = None\n",
        "    fallback_results = []\n",
        "    FAIL_MESSAGE = \"죄송합니다. 질문에 대한 정보를 찾을 수 없습니다. 조금 더 구체적인 상황을 추가해서 질문해주세요.\"\n",
        "    success_attempt = None\n",
        "\n",
        "    intent_result = intent_analysis(query)\n",
        "    if not intent_result['is_copyright_related']:\n",
        "        return \"저작권법과 관련된 질문을 해주세요. 다른 법령에 관한 질문은 답변하기 어렵습니다.\", [], None, [], \"기타\", \"기타\"\n",
        "\n",
        "    embeddings_model = OpenAIEmbeddings(\n",
        "        model=\"text-embedding-3-large\",\n",
        "        openai_api_key=OPENAI_API_KEY\n",
        "    )\n",
        "    vectorstore = FAISS.load_local(FAISS_INDEX_PATH, embeddings_model, allow_dangerous_deserialization=True)\n",
        "\n",
        "    llm = ChatOpenAI(\n",
        "        temperature=0,\n",
        "        model_name='gpt-4-turbo',\n",
        "        openai_api_key=OPENAI_API_KEY\n",
        "    )\n",
        "\n",
        "    retriever = MultiQueryRetriever.from_llm(\n",
        "        retriever=vectorstore.as_retriever(),\n",
        "        llm=llm\n",
        "    )\n",
        "\n",
        "    # ✅ 대화 제목, 카테고리, 관련 질문 한 번에 생성\n",
        "    metadata_prompt = f\"\"\"\n",
        "    다음은 사용자의 질문입니다:\n",
        "\n",
        "    \"{query}\"\n",
        "\n",
        "    이 질문에 대해 다음 항목을 순서대로 출력해주세요:\n",
        "\n",
        "    1. 대화 제목 (15자 이내, 따옴표 없이)\n",
        "    2. 카테고리 (한 단어나 짧은 문장)\n",
        "    3. 관련된 추가 질문 3가지 (줄바꿈으로 구분)\n",
        "\n",
        "    출력 예시:\n",
        "\n",
        "    제목: 유튜브 음악 저작권\n",
        "    카테고리: 음악저작권\n",
        "    관련 질문:\n",
        "    - 유튜브 영상에 배경음악으로 상업곡을 사용하면 문제가 되나요?\n",
        "    - 강의자료에 배경음악을 삽입해도 되나요?\n",
        "    - 다른 사람의 음악을 편집해서 써도 되나요?\n",
        "    \"\"\"\n",
        "    metadata_result = llm.predict(metadata_prompt).strip()\n",
        "    lines = metadata_result.splitlines()\n",
        "    title = lines[0].replace(\"제목:\", \"\").strip()\n",
        "    category = lines[1].replace(\"카테고리:\", \"\").strip()\n",
        "    related_questions = [line.replace(\"- \", \"\").strip() for line in lines[3:] if line.strip()]\n",
        "\n",
        "    model = AutoModel.from_pretrained(\n",
        "        'jinaai/jina-reranker-m0',\n",
        "        torch_dtype=\"auto\",\n",
        "        trust_remote_code=True,\n",
        "        attn_implementation=\"flash_attention_2\"\n",
        "    )\n",
        "    model.to(\"cuda\")\n",
        "\n",
        "    # ✅ 문서 필터 설정\n",
        "    document_type_filters = []\n",
        "    for doc_type in intent_result['document_types']:\n",
        "        if doc_type == \"법령\":\n",
        "            law_filter = {\"문서유형\": \"법령\"}\n",
        "            article_num = intent_result['specific_article'].get(\"article\")\n",
        "            ho_num = intent_result['specific_article'].get(\"ho\")\n",
        "            if article_num:\n",
        "                law_filter[\"조문번호\"] = f\"{article_num}조\"\n",
        "                if ho_num:\n",
        "                    law_filter[\"호번호\"] = ho_num\n",
        "            document_type_filters.append(law_filter)\n",
        "\n",
        "        elif doc_type == \"부칙\":\n",
        "            sub_filter = {\"문서유형\": \"부칙\"}\n",
        "            article_num = intent_result['specific_article'].get(\"article\")\n",
        "            if article_num:\n",
        "                sub_filter[\"조문번호\"] = f\"{article_num}조\"\n",
        "            document_type_filters.append(sub_filter)\n",
        "\n",
        "        elif doc_type == \"시행령\":\n",
        "            ord_filter = {\"문서유형\": \"시행령\"}\n",
        "            article_num = intent_result['specific_article'].get(\"article\")\n",
        "            ho_num = intent_result['specific_article'].get(\"ho\")\n",
        "            if article_num:\n",
        "                ord_filter[\"조문번호\"] = f\"{article_num}조\"\n",
        "                if ho_num:\n",
        "                    ord_filter[\"호번호\"] = ho_num\n",
        "            document_type_filters.append(ord_filter)\n",
        "\n",
        "        elif doc_type == \"판례\":\n",
        "            case_filter = {\"문서유형\": \"판례\"}\n",
        "            article_num = intent_result['specific_article'].get(\"article\")\n",
        "            ho_num = intent_result['specific_article'].get(\"ho\")\n",
        "            related_article = []\n",
        "            if article_num:\n",
        "                if ho_num:\n",
        "                    related_article.append(f\"저작권법 제{article_num}조 제{ho_num}호\")\n",
        "                else:\n",
        "                    related_article.append(f\"저작권법 제{article_num}조\")\n",
        "            if related_article:\n",
        "                case_filter[\"참조조문\"] = {\"$in\": related_article}\n",
        "            document_type_filters.append(case_filter)\n",
        "\n",
        "        elif doc_type == \"해석례\":\n",
        "            exp_filter = {\"문서유형\": \"해석례\"}\n",
        "            document_type_filters.append(exp_filter)\n",
        "\n",
        "    final_filter = {\"$or\": document_type_filters} if document_type_filters else {}\n",
        "    if final_filter:\n",
        "        vectorstore.as_retriever().search_kwargs[\"filter\"] = final_filter\n",
        "\n",
        "    while retry_count < MAX_RETRIES:\n",
        "        filtered_docs = generate_multiquery_and_retrieve(query, retry_count, retriever, llm, model)\n",
        "        final_answer, final_ref, evaluation_result = generate_answer_and_evaluate(query, filtered_docs, llm)\n",
        "\n",
        "        faithfulness = evaluation_result[\"faithfulness\"][0]\n",
        "        relevancy = evaluation_result[\"answer_relevancy\"][0]\n",
        "\n",
        "        if faithfulness >= 0.5 and relevancy >= 0.7:\n",
        "            final_result = final_answer\n",
        "            success_attempt = retry_count + 1\n",
        "            break\n",
        "        elif 0.1 < faithfulness < 0.5 and relevancy >= 0.8:\n",
        "            fallback_results.append({\n",
        "                \"answer\": final_answer,\n",
        "                \"docs\": filtered_docs,\n",
        "                \"final_ref\": final_ref,\n",
        "                \"faithfulness\": faithfulness,\n",
        "                \"relevancy\": relevancy,\n",
        "                \"retry\": retry_count + 1\n",
        "            })\n",
        "\n",
        "        retry_count += 1\n",
        "\n",
        "    if final_result:\n",
        "        success_message = f\"✅ {success_attempt}회차 시도에 정식 기준으로 답변이 생성되었습니다.\"\n",
        "        final_result_with_note = f\"{success_message}\\n\\n{final_result}\"\n",
        "        return final_result_with_note, final_result, filtered_docs, evaluation_result, related_questions, category, title\n",
        "\n",
        "    elif fallback_results:\n",
        "        best_fallback = max(fallback_results, key=lambda x: (x[\"relevancy\"] + x[\"faithfulness\"]))\n",
        "        fallback_msg = f\"\"\"⚠️ 정식 기준은 충족하지 못했지만 {best_fallback['retry']}회차 시도에 유사한 답변이 생성되었습니다:\\n\\n{best_fallback['answer']}\\n\\n※ 더 정확한 답변을 원하시면 질문을 조금 더 구체적으로 작성해 주세요.\"\"\"\n",
        "        return fallback_msg, best_fallback[\"answer\"], best_fallback[\"docs\"], evaluation_result, related_questions, category, title\n",
        "\n",
        "    else:\n",
        "        return FAIL_MESSAGE, FAIL_MESSAGE, [], None, related_questions, category, title\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JRTYPEjGnZlw",
        "outputId": "8bbd63a8-b1da-44a1-a322-263c94e5735d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting all_step.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Streamlit"
      ],
      "metadata": {
        "id": "0dhrHCo4T9pO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import re\n",
        "import time\n",
        "import json\n",
        "\n",
        "import openai\n",
        "from openai import OpenAI\n",
        "from config import OPENAI_API_KEY\n",
        "from intent_analysis import intent_analysis\n",
        "from generate_multiquery_and_retrieve import generate_multiquery_and_retrieve\n",
        "from generate_answer_and_evaluate import generate_answer_and_evaluate\n",
        "from all_step import all_step\n",
        "from utils import linkify_articles\n",
        "from google_sheets import append_feedback_to_sheet\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from sentence_transformers import CrossEncoder\n",
        "\n",
        "openai.api_key = OPENAI_API_KEY\n",
        "client = OpenAI(api_key=OPENAI_API_KEY)\n",
        "\n",
        "st.set_page_config(page_title=\"ASAC 법률자문 AI\", layout=\"wide\", page_icon=\"📚\")\n",
        "st.title(\"ASAC 저작권법 법률 자문에 오신 것을 환영합니다.\")\n",
        "\n",
        "st.markdown(\"\"\"\n",
        "<div style='font-size:18px; line-height:1.6'>\n",
        "저작권법 전문 생성형 AI가 법령, 판례, 해석례를 기반으로 신속하고 신뢰성 있는 자문을 제공합니다.<br><br>\n",
        "</div>\n",
        "\"\"\", unsafe_allow_html=True)\n",
        "\n",
        "st.markdown(\"\"\"\n",
        "<div style='font-size:15px; color:#888; border:1px solid #ddd; padding:10px; border-radius:5px; margin-bottom:10px;'>\n",
        "    <div style='font-size:20px; line-height:1.6; color:#888;'><b>📌 질문 예시</b></div>\n",
        "    <div>　　Q. 유튜브 영상에 다른 사람의 음악을 배경으로 쓰면 저작권 침해인가요?</div>\n",
        "    <div>　　Q. 허락 없이 써도 되는 저작물의 조건에 뭐가 있나요?</div>\n",
        "    <div>　　Q. 유튜브에 올리는 것과 개인 블로그에 쓰는 것 중 뭐가 더 문제인가요?</div>\n",
        "</div>\n",
        "\"\"\", unsafe_allow_html=True)\n",
        "\n",
        "# 세션 상태 초기화\n",
        "for key in [\"messages\", \"chat_sessions\", \"active_chat\", \"related_questions\", \"prompt_input\"]:\n",
        "    if key not in st.session_state:\n",
        "        st.session_state[key] = [] if key in [\"messages\", \"related_questions\"] else {} if key == \"chat_sessions\" else None\n",
        "\n",
        "# 사이드바\n",
        "with st.sidebar:\n",
        "    if st.button(\"➕ 새 대화\"):\n",
        "        st.session_state.messages = []\n",
        "        st.session_state.active_chat = \"대화 준비 중...\"\n",
        "        st.session_state.related_questions = []\n",
        "        st.session_state.prompt_input = None\n",
        "\n",
        "    st.subheader(\"📁 이전 대화\")\n",
        "    for title in reversed(list(st.session_state.chat_sessions.keys())):\n",
        "        if st.button(title):\n",
        "            st.session_state.messages = st.session_state.chat_sessions[title][\"messages\"]\n",
        "            st.session_state.active_chat = title\n",
        "            st.session_state.related_questions = st.session_state.chat_sessions[title].get(\"related\", [])\n",
        "            st.session_state.prompt_input = None\n",
        "\n",
        "# 사용자 입력\n",
        "user_input = st.chat_input(\"저작권법에 관한 궁금한 점을 입력하세요.\")\n",
        "if user_input:\n",
        "    st.session_state[\"prompt_input\"] = user_input\n",
        "\n",
        "# 질문이 들어온 경우 처리\n",
        "if st.session_state[\"prompt_input\"]:\n",
        "    prompt = st.session_state[\"prompt_input\"]\n",
        "    spinner = st.empty()\n",
        "    spinner.info(\"🧠 AI가 신중히 답변을 구성하고 있습니다...\")\n",
        "\n",
        "    try:\n",
        "        final_result_with_note, final_answer, source_docs, evaluation_result, related_questions, category, title = all_step(prompt)\n",
        "        st.session_state.related_questions = related_questions\n",
        "\n",
        "        st.session_state.messages.append({\"role\": \"user\", \"content\": prompt, \"source_docs\": []})\n",
        "        st.session_state.messages.append({\n",
        "            \"role\": \"assistant\",\n",
        "            \"content\": final_result_with_note,\n",
        "            \"source_docs\": source_docs\n",
        "        })\n",
        "\n",
        "        st.session_state.active_chat = title\n",
        "        st.session_state.chat_sessions[title] = {\n",
        "            \"messages\": st.session_state.messages,\n",
        "            \"category\": category,\n",
        "            \"related\": related_questions\n",
        "        }\n",
        "\n",
        "        spinner.empty()\n",
        "\n",
        "    except Exception as e:\n",
        "        spinner.empty()\n",
        "        st.error(f\"❌ 오류 발생: {e}\")\n",
        "        st.stop()\n",
        "\n",
        "    finally:\n",
        "        st.session_state[\"prompt_input\"] = None\n",
        "\n",
        "# 채팅 메시지 출력\n",
        "if st.session_state.active_chat and st.session_state.active_chat != \"대화 준비 중...\":\n",
        "    category = st.session_state.chat_sessions[st.session_state.active_chat].get(\"category\", \"기타\")\n",
        "    if not category or not category.strip():\n",
        "        category = \"기타\"\n",
        "    st.markdown(f\"📂 **카테고리:** `{category}`\")\n",
        "\n",
        "    with st.container():\n",
        "        for idx, msg in enumerate(st.session_state.messages):\n",
        "            with st.chat_message(msg[\"role\"]):\n",
        "                st.markdown(linkify_articles(msg[\"content\"]), unsafe_allow_html=True)\n",
        "\n",
        "                if msg[\"role\"] == \"assistant\" and \"source_docs\" in msg:\n",
        "                    st.markdown(\"📎 **참조 문서 목록**\")\n",
        "                    for i, doc in enumerate(msg[\"source_docs\"]):\n",
        "                        doc_type = doc.metadata.get(\"문서유형\", \"문서\")\n",
        "                        type_icon_map = {\n",
        "                          \"판례\": \"📄\",\n",
        "                          \"해석례\": \"📘\",\n",
        "                          \"법령\": \"📜\",\n",
        "                          \"시행령\": \"📑\",\n",
        "                          \"부칙\": \"📂\",\n",
        "                        }\n",
        "                        icon = type_icon_map.get(doc_type, \"📎\")\n",
        "                        label = f\"{icon} {doc_type or '문서'} {i+1}\"\n",
        "                        st.write(f\"**{label}**\")\n",
        "                        st.write(doc.page_content[:300] + \"...\")\n",
        "                        visible_keys = ['사건명', '사건번호', '선고일자', '법원명']\n",
        "                        meta = {k: v for k, v in doc.metadata.items() if k in visible_keys}\n",
        "\n",
        "                        if meta:\n",
        "                            court = meta.get('법원명', '')\n",
        "                            case_title = meta.get('사건명', '')\n",
        "                            case_number = meta.get('사건번호', '')\n",
        "                            date = meta.get('선고일자', '')\n",
        "\n",
        "                            summary = f\"\"\"\n",
        "                            <div style='background-color:#f9f9f9; color:green; border:1px solid #ddd; padding:10px; border-radius:5px; margin-bottom:10px;'>\n",
        "                            📄 {date}에 {court}에서 '{case_title}' 사건({case_number})에 대한 판결입니다.\n",
        "                            </div>\n",
        "                            \"\"\"\n",
        "                            st.markdown(summary, unsafe_allow_html=True)\n",
        "\n",
        "                if msg[\"role\"] == \"assistant\":\n",
        "                    feedback_key = f\"feedback_{idx}\"\n",
        "                    if not st.session_state.get(feedback_key):\n",
        "                        with st.expander(\"이 답변이 도움이 되었나요?\"):\n",
        "                            col1, col2, col3 = st.columns(3)\n",
        "                            with col1:\n",
        "                                if st.button(\"👍 도움이 됐어요\", key=f\"helpful_{idx}\"):\n",
        "                                    append_feedback_to_sheet(\"도움이 됐어요\", msg[\"content\"], st.session_state.active_chat)\n",
        "                                    st.success(\"감사합니다.\")\n",
        "                                    st.session_state[feedback_key] = True\n",
        "                            with col2:\n",
        "                                if st.button(\"👎 더 궁금해요\", key=f\"more_info_{idx}\"):\n",
        "                                    append_feedback_to_sheet(\"더 궁금해요\", msg[\"content\"], st.session_state.active_chat)\n",
        "                                    st.success(\"추가 개선하게사합니다.\")\n",
        "                                    st.session_state[feedback_key] = True\n",
        "                            with col3:\n",
        "                                if st.button(\"🤔 이해가 어렵습니다\", key=f\"difficult_{idx}\"):\n",
        "                                    append_feedback_to_sheet(\"이해 어렵습니다\", msg[\"content\"], st.session_state.active_chat)\n",
        "                                    st.success(\"도움 주셔서 감사합니다.\")\n",
        "                                    st.session_state[feedback_key] = True\n",
        "\n",
        "    valid_related = [q for q in st.session_state.related_questions if q.strip()]\n",
        "    if valid_related:\n",
        "        st.markdown(\"📚 **추가로 궁금할 수 있는 질문**\")\n",
        "        for idx, q in enumerate(valid_related[:3]):\n",
        "            if st.button(q, key=f\"related_q_{idx}\"):\n",
        "                st.session_state[\"prompt_input\"] = q\n",
        "else:\n",
        "    st.info(\"왼쪽에서 대화를 선택하거나 새 대화를 시작하세요.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QGsDufPkc87L",
        "outputId": "4ed3f458-34b3-446a-96e6-583249b8aa27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyngrok\n",
        "!pip install streamlit"
      ],
      "metadata": {
        "id": "zgt25RHl3PtH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28a1ce35-366e-4ce7-9526-1be719919dea",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.11/dist-packages (7.2.8)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n",
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.11/dist-packages (1.45.1)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.2.0)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (24.2)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.2.1)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.29.4)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (9.1.2)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.13.2)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.44)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.9.1)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.39.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2025.4.26)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.24.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !ngrok authtoken \"2v76lh7I7WduDxuyx8tqMtHWaPB_7zmsD78Fh8NQy9KBzfE1C\" #내꺼1\n",
        "!ngrok authtoken \"2wWlfT7uTD4KMIX6XQGifLtZDpj_3tQ5r1nAEpwsGHnRuyEN8\" #희련"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZeEnMDyxvhpZ",
        "outputId": "cb58708b-a566-4966-c5c0-9ff0331b0c5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pkill -9 ngrok\n",
        "!pkill -9 streamlit"
      ],
      "metadata": {
        "id": "HzR-N5uRfi-d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "import subprocess\n",
        "\n",
        "# 기존 ngrok 프로세스 종료\n",
        "ngrok.kill()\n",
        "\n",
        "# Streamlit 실행\n",
        "command = \"streamlit run app.py --server.port 8501 &\"\n",
        "process = subprocess.Popen(command, shell=True)\n",
        "\n",
        "# ngrok 터널 생성 (포트 설정 변경)\n",
        "public_url = ngrok.connect(addr=\"8501\", proto=\"http\")\n",
        "print(f\"Streamlit 앱이 실행되었습니다! {public_url}\")\n"
      ],
      "metadata": {
        "id": "0VgkSYPJvwfK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86b7e5ae-7016-4a98-fe60-9d8923499e1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Streamlit 앱이 실행되었습니다! NgrokTunnel: \"https://5f41-34-87-124-247.ngrok-free.app\" -> \"http://localhost:8501\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "71CORkXTBQCH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}